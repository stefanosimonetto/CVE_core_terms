{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train based on CVE terms with Phi-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "260/260 [==============================] - 0s 966us/steposs: 2.2160 - accurac\n",
      "Epoch 1 - F1 Score: 0.4825\n",
      "Saved best model\n",
      "[0.48247620185550677]\n",
      "2336/2336 [==============================] - 20s 8ms/step - loss: 2.2151 - accuracy: 0.4270 - val_loss: 1.7855 - val_accuracy: 0.5119\n",
      "Epoch 2/40\n",
      "260/260 [==============================] - 1s 3ms/step los\n",
      "Epoch 2 - F1 Score: 0.5293\n",
      "Saved best model\n",
      "[0.48247620185550677, 0.5293309841606527]\n",
      "2336/2336 [==============================] - 18s 8ms/step - loss: 1.6957 - accuracy: 0.5389 - val_loss: 1.6051 - val_accuracy: 0.5609\n",
      "Epoch 3/40\n",
      "260/260 [==============================] - 1s 3ms/step lo\n",
      "Epoch 3 - F1 Score: 0.5408\n",
      "Saved best model\n",
      "[0.48247620185550677, 0.5293309841606527, 0.540845384508342]\n",
      "2336/2336 [==============================] - 20s 8ms/step - loss: 1.5833 - accuracy: 0.5661 - val_loss: 1.5666 - val_accuracy: 0.5726\n",
      "Epoch 4/40\n",
      "260/260 [==============================] - 1s 3ms/step \n",
      "Epoch 4 - F1 Score: 0.5578\n",
      "Saved best model\n",
      "[0.48247620185550677, 0.5293309841606527, 0.540845384508342, 0.5578148681835082]\n",
      "2336/2336 [==============================] - 24s 10ms/step - loss: 1.5223 - accuracy: 0.5798 - val_loss: 1.5429 - val_accuracy: 0.5773\n",
      "Epoch 5/40\n",
      "260/260 [==============================] - 1s 2ms/step loss: 1\n",
      "Epoch 5 - F1 Score: 0.5708\n",
      "Saved best model\n",
      "[0.48247620185550677, 0.5293309841606527, 0.540845384508342, 0.5578148681835082, 0.570842212693147]\n",
      "2336/2336 [==============================] - 23s 10ms/step - loss: 1.4719 - accuracy: 0.5927 - val_loss: 1.5061 - val_accuracy: 0.5888\n",
      "Epoch 6/40\n",
      "260/260 [==============================] - 1s 3ms/step l\n",
      "Epoch 6 - F1 Score: 0.5753\n",
      "Saved best model\n",
      "[0.48247620185550677, 0.5293309841606527, 0.540845384508342, 0.5578148681835082, 0.570842212693147, 0.5753379137801508]\n",
      "2336/2336 [==============================] - 17s 7ms/step - loss: 1.4416 - accuracy: 0.6011 - val_loss: 1.4652 - val_accuracy: 0.5976\n",
      "Epoch 7/40\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "Epoch 7 - F1 Score: 0.5756\n",
      "Saved best model\n",
      "[0.48247620185550677, 0.5293309841606527, 0.540845384508342, 0.5578148681835082, 0.570842212693147, 0.5753379137801508, 0.5756110124947769]\n",
      "2336/2336 [==============================] - 17s 7ms/step - loss: 1.4195 - accuracy: 0.6046 - val_loss: 1.5196 - val_accuracy: 0.5868\n",
      "Epoch 8/40\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "2336/2336 [==============================] - 18s 8ms/step - loss: 1.3996 - accuracy: 0.6099 - val_loss: 1.5605 - val_accuracy: 0.5757\n",
      "Epoch 9/40\n",
      "260/260 [==============================] - 1s 2ms/step loss: 1.382\n",
      "Epoch 9 - F1 Score: 0.5807\n",
      "Saved best model\n",
      "[0.48247620185550677, 0.5293309841606527, 0.540845384508342, 0.5578148681835082, 0.570842212693147, 0.5753379137801508, 0.5756110124947769, 0.5658378049146482, 0.5806702757712147]\n",
      "2336/2336 [==============================] - 17s 7ms/step - loss: 1.3822 - accuracy: 0.6154 - val_loss: 1.5159 - val_accuracy: 0.5888\n",
      "Epoch 10/40\n",
      "260/260 [==============================] - 1s 3ms/step l\n",
      "Epoch 10 - F1 Score: 0.5968\n",
      "Saved best model\n",
      "[0.48247620185550677, 0.5293309841606527, 0.540845384508342, 0.5578148681835082, 0.570842212693147, 0.5753379137801508, 0.5756110124947769, 0.5658378049146482, 0.5806702757712147, 0.5968035431545745]\n",
      "2336/2336 [==============================] - 18s 8ms/step - loss: 1.3638 - accuracy: 0.6177 - val_loss: 1.4135 - val_accuracy: 0.6088\n",
      "Epoch 11/40\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "2336/2336 [==============================] - 17s 7ms/step - loss: 1.3508 - accuracy: 0.6217 - val_loss: 1.4735 - val_accuracy: 0.5973\n",
      "Epoch 12/40\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "2336/2336 [==============================] - 18s 8ms/step - loss: 1.3358 - accuracy: 0.6251 - val_loss: 1.3964 - val_accuracy: 0.6115\n",
      "Epoch 13/40\n",
      "260/260 [==============================] - 1s 3ms/step l\n",
      "Epoch 13 - F1 Score: 0.5992\n",
      "Saved best model\n",
      "[0.48247620185550677, 0.5293309841606527, 0.540845384508342, 0.5578148681835082, 0.570842212693147, 0.5753379137801508, 0.5756110124947769, 0.5658378049146482, 0.5806702757712147, 0.5968035431545745, 0.5820039649330105, 0.5948048697711298, 0.5991811891113312]\n",
      "2336/2336 [==============================] - 18s 8ms/step - loss: 1.3240 - accuracy: 0.6271 - val_loss: 1.4109 - val_accuracy: 0.6164\n",
      "Epoch 14/40\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "2336/2336 [==============================] - 24s 10ms/step - loss: 1.3173 - accuracy: 0.6289 - val_loss: 1.4628 - val_accuracy: 0.6041\n",
      "Epoch 15/40\n",
      "260/260 [==============================] - 1s 3ms/step \n",
      "Epoch 15 - F1 Score: 0.6010\n",
      "Saved best model\n",
      "[0.48247620185550677, 0.5293309841606527, 0.540845384508342, 0.5578148681835082, 0.570842212693147, 0.5753379137801508, 0.5756110124947769, 0.5658378049146482, 0.5806702757712147, 0.5968035431545745, 0.5820039649330105, 0.5948048697711298, 0.5991811891113312, 0.592668272360926, 0.6010184915202204]\n",
      "2336/2336 [==============================] - 25s 11ms/step - loss: 1.3022 - accuracy: 0.6338 - val_loss: 1.4232 - val_accuracy: 0.6151\n",
      "Epoch 16/40\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "2336/2336 [==============================] - 25s 11ms/step - loss: 1.2976 - accuracy: 0.6340 - val_loss: 1.4783 - val_accuracy: 0.6010\n",
      "Epoch 17/40\n",
      "260/260 [==============================] - 1s 3ms/step \n",
      "Epoch 17 - F1 Score: 0.6019\n",
      "Saved best model\n",
      "[0.48247620185550677, 0.5293309841606527, 0.540845384508342, 0.5578148681835082, 0.570842212693147, 0.5753379137801508, 0.5756110124947769, 0.5658378049146482, 0.5806702757712147, 0.5968035431545745, 0.5820039649330105, 0.5948048697711298, 0.5991811891113312, 0.592668272360926, 0.6010184915202204, 0.5896738050863787, 0.6018552811734585]\n",
      "2336/2336 [==============================] - 25s 11ms/step - loss: 1.2882 - accuracy: 0.6358 - val_loss: 1.4506 - val_accuracy: 0.6112\n",
      "Epoch 18/40\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "Epoch 18 - F1 Score: 0.6204\n",
      "Saved best model\n",
      "[0.48247620185550677, 0.5293309841606527, 0.540845384508342, 0.5578148681835082, 0.570842212693147, 0.5753379137801508, 0.5756110124947769, 0.5658378049146482, 0.5806702757712147, 0.5968035431545745, 0.5820039649330105, 0.5948048697711298, 0.5991811891113312, 0.592668272360926, 0.6010184915202204, 0.5896738050863787, 0.6018552811734585, 0.6204158961152804]\n",
      "2336/2336 [==============================] - 25s 11ms/step - loss: 1.2814 - accuracy: 0.6389 - val_loss: 1.3916 - val_accuracy: 0.6275\n",
      "Epoch 19/40\n",
      "260/260 [==============================] - 1s 3ms/step lo\n",
      "2336/2336 [==============================] - 25s 11ms/step - loss: 1.2740 - accuracy: 0.6393 - val_loss: 1.3939 - val_accuracy: 0.6216\n",
      "Epoch 20/40\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "2336/2336 [==============================] - 24s 10ms/step - loss: 1.2673 - accuracy: 0.6393 - val_loss: 1.4240 - val_accuracy: 0.6153\n",
      "Epoch 21/40\n",
      "260/260 [==============================] - 1s 3ms/step loss: \n",
      "2336/2336 [==============================] - 26s 11ms/step - loss: 1.2608 - accuracy: 0.6440 - val_loss: 1.4117 - val_accuracy: 0.6171\n",
      "Epoch 22/40\n",
      "260/260 [==============================] - 1s 3ms/step los\n",
      "2336/2336 [==============================] - 25s 11ms/step - loss: 1.2584 - accuracy: 0.6437 - val_loss: 1.4216 - val_accuracy: 0.6128\n",
      "Epoch 23/40\n",
      "260/260 [==============================] - 1s 3ms/step los\n",
      "2336/2336 [==============================] - 24s 10ms/step - loss: 1.2515 - accuracy: 0.6453 - val_loss: 1.4629 - val_accuracy: 0.6097\n",
      "Epoch 24/40\n",
      "260/260 [==============================] - 1s 3ms/step loss\n",
      "2336/2336 [==============================] - 24s 10ms/step - loss: 1.2418 - accuracy: 0.6480 - val_loss: 1.5146 - val_accuracy: 0.5997\n",
      "Epoch 25/40\n",
      "260/260 [==============================] - 1s 3ms/step lo\n",
      "2336/2336 [==============================] - 25s 11ms/step - loss: 1.2410 - accuracy: 0.6459 - val_loss: 1.4359 - val_accuracy: 0.6124\n",
      "Epoch 26/40\n",
      "260/260 [==============================] - 1s 3ms/step los\n",
      "2336/2336 [==============================] - 25s 11ms/step - loss: 1.2360 - accuracy: 0.6468 - val_loss: 1.4111 - val_accuracy: 0.6193\n",
      "Epoch 27/40\n",
      "260/260 [==============================] - 1s 3ms/step los\n",
      "2336/2336 [==============================] - 24s 10ms/step - loss: 1.2316 - accuracy: 0.6486 - val_loss: 1.3994 - val_accuracy: 0.6180\n",
      "Epoch 28/40\n",
      "260/260 [==============================] - 1s 3ms/step loss\n",
      "2336/2336 [==============================] - 25s 11ms/step - loss: 1.2248 - accuracy: 0.6510 - val_loss: 1.5537 - val_accuracy: 0.5897\n",
      "Epoch 29/40\n",
      "260/260 [==============================] - 1s 3ms/step los\n",
      "2336/2336 [==============================] - 25s 10ms/step - loss: 1.2207 - accuracy: 0.6512 - val_loss: 1.4333 - val_accuracy: 0.6182\n",
      "Epoch 30/40\n",
      "260/260 [==============================] - 1s 3ms/step loss:\n",
      "2336/2336 [==============================] - 24s 10ms/step - loss: 1.2185 - accuracy: 0.6519 - val_loss: 1.3901 - val_accuracy: 0.6294\n",
      "Epoch 31/40\n",
      "260/260 [==============================] - 1s 3ms/step loss: \n",
      "2336/2336 [==============================] - 26s 11ms/step - loss: 1.2174 - accuracy: 0.6524 - val_loss: 1.3904 - val_accuracy: 0.6222\n",
      "Epoch 32/40\n",
      "260/260 [==============================] - 1s 3ms/step los\n",
      "2336/2336 [==============================] - 23s 10ms/step - loss: 1.2103 - accuracy: 0.6544 - val_loss: 1.4892 - val_accuracy: 0.6075\n",
      "Epoch 33/40\n",
      "260/260 [==============================] - 1s 2ms/step loss: 1.205\n",
      "2336/2336 [==============================] - 13s 6ms/step - loss: 1.2058 - accuracy: 0.6573 - val_loss: 1.4343 - val_accuracy: 0.6189\n",
      "Epoch 34/40\n",
      "260/260 [==============================] - 1s 3ms/step loss:\n",
      "2336/2336 [==============================] - 18s 8ms/step - loss: 1.1999 - accuracy: 0.6559 - val_loss: 1.4302 - val_accuracy: 0.6134\n",
      "Epoch 35/40\n",
      "260/260 [==============================] - 1s 2ms/step loss: 1.196\n",
      "2336/2336 [==============================] - 18s 8ms/step - loss: 1.1969 - accuracy: 0.6575 - val_loss: 1.4206 - val_accuracy: 0.6119\n",
      "Epoch 36/40\n",
      "260/260 [==============================] - 1s 2ms/step loss: 1.190\n",
      "2336/2336 [==============================] - 19s 8ms/step - loss: 1.1908 - accuracy: 0.6593 - val_loss: 1.4564 - val_accuracy: 0.6130\n",
      "Epoch 37/40\n",
      "260/260 [==============================] - 1s 2ms/step loss: 1.195\n",
      "Epoch 37 - F1 Score: 0.6233\n",
      "Saved best model\n",
      "[0.48247620185550677, 0.5293309841606527, 0.540845384508342, 0.5578148681835082, 0.570842212693147, 0.5753379137801508, 0.5756110124947769, 0.5658378049146482, 0.5806702757712147, 0.5968035431545745, 0.5820039649330105, 0.5948048697711298, 0.5991811891113312, 0.592668272360926, 0.6010184915202204, 0.5896738050863787, 0.6018552811734585, 0.6204158961152804, 0.6112576660091407, 0.6042010435824998, 0.6072771939201692, 0.600851547492134, 0.5984286819857431, 0.5872475031134026, 0.6027447936238043, 0.6084918863111329, 0.6079709701924708, 0.5801617146156095, 0.6050272034763627, 0.6169475221101631, 0.6105898775400431, 0.6001918635534653, 0.6120392292789281, 0.5991963578018603, 0.6055672878203813, 0.6030726449508803, 0.6233072663090367]\n",
      "2336/2336 [==============================] - 20s 9ms/step - loss: 1.1952 - accuracy: 0.6570 - val_loss: 1.3918 - val_accuracy: 0.6309\n",
      "Epoch 38/40\n",
      "260/260 [==============================] - 0s 2ms/step loss: 1.1890 \n",
      "2336/2336 [==============================] - 17s 7ms/step - loss: 1.1896 - accuracy: 0.6561 - val_loss: 1.4516 - val_accuracy: 0.6099\n",
      "Epoch 39/40\n",
      "260/260 [==============================] - 1s 2ms/step loss: 1\n",
      "2336/2336 [==============================] - 18s 8ms/step - loss: 1.1855 - accuracy: 0.6594 - val_loss: 1.4277 - val_accuracy: 0.6252\n",
      "Epoch 40/40\n",
      "260/260 [==============================] - 1s 4ms/step\n",
      "2336/2336 [==============================] - 17s 7ms/step - loss: 1.1829 - accuracy: 0.6598 - val_loss: 1.4207 - val_accuracy: 0.6245\n",
      "444/444 [==============================] - 1s 3ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.7070    0.5075    0.5909      1070\n",
      "         120     0.4062    0.5306    0.4602       196\n",
      "         125     0.8287    0.7820    0.8046       532\n",
      "         134     0.5714    0.8421    0.6809        19\n",
      "         189     0.5148    0.7311    0.6042       119\n",
      "         190     0.6957    0.7200    0.7076       200\n",
      "          20     0.4424    0.1802    0.2561       810\n",
      "         200     0.5134    0.5508    0.5315       590\n",
      "         203     0.4848    0.5926    0.5333        27\n",
      "          22     0.8339    0.9015    0.8664       518\n",
      "         254     0.0000    0.0000    0.0000        34\n",
      "         255     0.5517    0.2388    0.3333        67\n",
      "         264     0.5017    0.2922    0.3693       503\n",
      "         269     0.2892    0.4528    0.3529       106\n",
      "         276     0.2035    0.3594    0.2599        64\n",
      "         284     0.4000    0.0813    0.1351       123\n",
      "         287     0.4462    0.6842    0.5402       285\n",
      "         295     0.5085    0.3704    0.4286        81\n",
      "         306     0.2222    0.1064    0.1439        94\n",
      "         310     0.5676    0.7590    0.6495       249\n",
      "         312     0.2222    0.1429    0.1739        42\n",
      "         319     0.4909    0.5294    0.5094        51\n",
      "         326     0.1389    0.1613    0.1493        31\n",
      "         327     0.2099    0.4857    0.2931        35\n",
      "         345     0.2000    0.0385    0.0645        26\n",
      "         347     0.3333    0.3333    0.3333        24\n",
      "         352     0.8294    0.9338    0.8785       453\n",
      "         362     0.7719    0.7213    0.7458       122\n",
      "         399     0.2508    0.5954    0.3529       262\n",
      "         400     0.1866    0.5435    0.2778       138\n",
      "         401     0.4590    0.5385    0.4956        52\n",
      "         415     0.7586    0.5238    0.6197        42\n",
      "         416     0.9141    0.7200    0.8055       325\n",
      "         426     0.6176    0.5000    0.5526        42\n",
      "         427     0.4828    0.6364    0.5490        44\n",
      "         434     0.7183    0.7887    0.7518       194\n",
      "         476     0.8000    0.7713    0.7854       223\n",
      "         502     0.3546    0.8318    0.4972       107\n",
      "         522     0.3827    0.6889    0.4921        90\n",
      "         532     0.3000    0.6136    0.4030        44\n",
      "          59     0.7248    0.7248    0.7248       109\n",
      "         601     0.6494    0.7042    0.6757        71\n",
      "         611     0.7222    0.8478    0.7800        92\n",
      "         617     0.5238    0.5789    0.5500        38\n",
      "         639     0.2381    0.5357    0.3297        28\n",
      "         668     0.0303    0.0222    0.0256        45\n",
      "         732     0.2881    0.1735    0.2166        98\n",
      "          74     0.1154    0.2958    0.1660        71\n",
      "         755     0.2222    0.0714    0.1081        28\n",
      "          77     0.4854    0.3378    0.3984       148\n",
      "         770     0.1702    0.1356    0.1509        59\n",
      "         772     0.5455    0.1765    0.2667        34\n",
      "          78     0.4745    0.7230    0.5730       296\n",
      "         787     0.6864    0.6393    0.6620       890\n",
      "          79     0.9951    0.8045    0.8897      2256\n",
      "         798     0.8333    0.6202    0.7111       129\n",
      "         835     0.5660    0.7317    0.6383        41\n",
      "         843     0.8846    0.6765    0.7667        34\n",
      "         862     0.8130    0.4545    0.5831       220\n",
      "         863     0.2488    0.4237    0.3135       118\n",
      "          89     0.9871    0.8819    0.9316       957\n",
      "         908     0.4643    0.5417    0.5000        24\n",
      "         918     0.8675    0.8000    0.8324        90\n",
      "          94     0.3453    0.6575    0.4528       292\n",
      "\n",
      "    accuracy                         0.6284     14202\n",
      "   macro avg     0.4999    0.5209    0.4879     14202\n",
      "weighted avg     0.6755    0.6284    0.6342     14202\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_train_terms.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super(F1ScoreCallback, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_f1 = 0.0\n",
    "        self.best_model = None\n",
    "        self.f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_val_pred = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        f1 = f1_score(self.y_val, y_val_pred, average='weighted')\n",
    "        self.f1_scores.append(f1)\n",
    "        \n",
    "\n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "            self.best_model = self.model\n",
    "            print(f\"Epoch {epoch + 1} - F1 Score: {f1:.4f}\")\n",
    "            print(\"Saved best model\")\n",
    "            print(self.f1_scores)\n",
    "\n",
    "with open('phi_terms_comparison_train.pickle', 'rb') as f1:\n",
    "    balanced = pickle.load(f1)\n",
    "\n",
    "with open('phi_terms_comparison_test_0.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "train = np.array([item['cve_terms_phi'] for item in balanced if item['cwe'] != 'None'])\n",
    "test = np.array([item['cwe'] for item in balanced if item['cwe'] != 'None'])\n",
    "np.random.seed(42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,test,test_size=0.1,random_state=42)\n",
    "\n",
    "X_test = np.array([item['cve_terms_phi'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "label_encoder_train = LabelEncoder()\n",
    "y_train_encoded = label_encoder_train.fit_transform(y_train)\n",
    "label_encoder_test = LabelEncoder()\n",
    "y_test_encoded = label_encoder_test.fit_transform(y_test)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1_callback = F1ScoreCallback(X_val, label_encoder_train.transform(y_val))\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, epochs=40, batch_size=32, validation_data=(X_val, label_encoder_train.transform(y_val)), verbose=1, callbacks=[f1_callback])\n",
    "\n",
    "best_model = f1_callback.best_model\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'best_model_terms.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))\n",
    "\n",
    "joblib.dump(label_encoder_train, 'label_encoder_train_terms.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference CVE terms with Phi-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444/444 [==============================] - 9s 19ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.7070    0.5075    0.5909      1070\n",
      "         120     0.4062    0.5306    0.4602       196\n",
      "         125     0.8287    0.7820    0.8046       532\n",
      "         134     0.5714    0.8421    0.6809        19\n",
      "         189     0.5148    0.7311    0.6042       119\n",
      "         190     0.6957    0.7200    0.7076       200\n",
      "          20     0.4424    0.1802    0.2561       810\n",
      "         200     0.5134    0.5508    0.5315       590\n",
      "         203     0.4848    0.5926    0.5333        27\n",
      "          22     0.8339    0.9015    0.8664       518\n",
      "         254     0.0000    0.0000    0.0000        34\n",
      "         255     0.5517    0.2388    0.3333        67\n",
      "         264     0.5017    0.2922    0.3693       503\n",
      "         269     0.2892    0.4528    0.3529       106\n",
      "         276     0.2035    0.3594    0.2599        64\n",
      "         284     0.4000    0.0813    0.1351       123\n",
      "         287     0.4462    0.6842    0.5402       285\n",
      "         295     0.5085    0.3704    0.4286        81\n",
      "         306     0.2222    0.1064    0.1439        94\n",
      "         310     0.5676    0.7590    0.6495       249\n",
      "         312     0.2222    0.1429    0.1739        42\n",
      "         319     0.4909    0.5294    0.5094        51\n",
      "         326     0.1389    0.1613    0.1493        31\n",
      "         327     0.2099    0.4857    0.2931        35\n",
      "         345     0.2000    0.0385    0.0645        26\n",
      "         347     0.3333    0.3333    0.3333        24\n",
      "         352     0.8294    0.9338    0.8785       453\n",
      "         362     0.7719    0.7213    0.7458       122\n",
      "         399     0.2508    0.5954    0.3529       262\n",
      "         400     0.1866    0.5435    0.2778       138\n",
      "         401     0.4590    0.5385    0.4956        52\n",
      "         415     0.7586    0.5238    0.6197        42\n",
      "         416     0.9141    0.7200    0.8055       325\n",
      "         426     0.6176    0.5000    0.5526        42\n",
      "         427     0.4828    0.6364    0.5490        44\n",
      "         434     0.7183    0.7887    0.7518       194\n",
      "         476     0.8000    0.7713    0.7854       223\n",
      "         502     0.3546    0.8318    0.4972       107\n",
      "         522     0.3827    0.6889    0.4921        90\n",
      "         532     0.3000    0.6136    0.4030        44\n",
      "          59     0.7248    0.7248    0.7248       109\n",
      "         601     0.6494    0.7042    0.6757        71\n",
      "         611     0.7222    0.8478    0.7800        92\n",
      "         617     0.5238    0.5789    0.5500        38\n",
      "         639     0.2381    0.5357    0.3297        28\n",
      "         668     0.0303    0.0222    0.0256        45\n",
      "         732     0.2881    0.1735    0.2166        98\n",
      "          74     0.1154    0.2958    0.1660        71\n",
      "         755     0.2222    0.0714    0.1081        28\n",
      "          77     0.4854    0.3378    0.3984       148\n",
      "         770     0.1702    0.1356    0.1509        59\n",
      "         772     0.5455    0.1765    0.2667        34\n",
      "          78     0.4745    0.7230    0.5730       296\n",
      "         787     0.6864    0.6393    0.6620       890\n",
      "          79     0.9951    0.8045    0.8897      2256\n",
      "         798     0.8333    0.6202    0.7111       129\n",
      "         835     0.5660    0.7317    0.6383        41\n",
      "         843     0.8846    0.6765    0.7667        34\n",
      "         862     0.8130    0.4545    0.5831       220\n",
      "         863     0.2488    0.4237    0.3135       118\n",
      "          89     0.9871    0.8819    0.9316       957\n",
      "         908     0.4643    0.5417    0.5000        24\n",
      "         918     0.8675    0.8000    0.8324        90\n",
      "          94     0.3453    0.6575    0.4528       292\n",
      "\n",
      "    accuracy                         0.6284     14202\n",
      "   macro avg     0.4999    0.5209    0.4879     14202\n",
      "weighted avg     0.6755    0.6284    0.6342     14202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Save the best model\n",
    "with open('phi_terms_comparison_test_0.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "X_test = np.array([item['cve_terms_phi'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "best_model=joblib.load('best_model_terms.joblib')\n",
    "label_encoder_train=joblib.load('label_encoder_train_terms.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train based on CVE descriptions with Phi-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cve_id': 'CVE-1999-0007', 'cve_description': 'Information from SSL-encrypted sessions via PKCS #1.', 'cve_terms': ['SSL Encryption Vulnerability', 'PKCS #1 Exposure', 'Information Disclosure'], 'cwe': '327', 'cwe_class': '327', 'cve_description_phi': [1.087753176689148, 0.26409363746643066, 0.8230777382850647, -0.3850973844528198, -0.7270230054855347, 0.7219997644424438, 0.2268471121788025, 0.16935373842716217, -1.2603179216384888, 1.5379236936569214, 0.23670989274978638, -0.6104186773300171, -1.275844931602478, -1.0017726421356201, 0.15842241048812866, -0.1283402144908905, -0.19288694858551025, 1.2531225681304932, -0.8090196847915649, -0.10320411622524261, -0.9572002291679382, 1.0826053619384766, 0.5547383427619934, -0.0780240148305893, -0.5427049994468689, 0.13996493816375732, -1.0220403671264648, -2.688271999359131, 1.9150744676589966, 1.6416929960250854, 0.14876103401184082, 0.4220753610134125, 0.7890188694000244, 0.6650851964950562, 1.0920637845993042, -2.4817707538604736, 0.24820753931999207, -2.126173734664917, 0.9403831362724304, -0.2125256359577179, 1.20366632938385, -0.07592710107564926, 0.034851521253585815, -0.03282839059829712, -0.050071004778146744, -2.0875027179718018, 0.3838275372982025, -0.15077416598796844, -1.2145512104034424, 0.6927506923675537, 0.2133103609085083, 2.6284091472625732, 0.7029088139533997, 1.4287517070770264, -0.8869020342826843, 0.6958432197570801, 1.2677910327911377, 0.37956830859184265, -0.7177257537841797, -0.34355485439300537, 0.32506200671195984, -0.24159321188926697, 1.9448769092559814, 0.20809175074100494, -1.0652176141738892, 2.5440542697906494, 0.2853485941886902, -1.6881446838378906, -0.39439189434051514, -2.3080146312713623, 0.10462581366300583, -0.5131381750106812, 1.038307785987854, -0.7320777177810669, -0.3736666440963745, 1.63141667842865, 1.950654149055481, 0.2540229856967926, -1.6365753412246704, 0.7305353879928589, 2.008253812789917, -0.7595545053482056, 1.145897626876831, 0.6584846377372742, -1.290900707244873, 0.15201853215694427, -0.008919090032577515, -0.1429893970489502, -0.7619760632514954, 0.29830363392829895, -0.4188748896121979, 0.16058243811130524, -0.29495272040367126, -0.3051862120628357, 0.7211712598800659, -0.3276823163032532, 1.084626317024231, 0.1475774347782135, 1.3983105421066284, 0.7868317365646362, -0.015549469739198685, 0.873848021030426, -0.316210001707077, 0.9021198153495789, -1.2283263206481934, -2.051758050918579, 3.0203423500061035, 0.6198440194129944, -0.5460506677627563, 0.45730501413345337, -2.1652045249938965, 0.915187656879425, -0.6864408254623413, -2.42889666557312, 1.6400117874145508, 1.739099383354187, 0.2119067758321762, 1.3708394765853882, 1.1373417377471924, 0.09136702120304108, -0.5849836468696594, 1.1717946529388428, 0.9771352410316467, 0.1698985993862152, 1.3383373022079468, 2.233368396759033, -0.7331550121307373, 1.2153167724609375, 0.13649365305900574, 0.313254177570343, 1.7425543069839478, -1.2131903171539307, -0.4822612702846527, 1.3871750831604004, 0.46574512124061584, 0.9450331330299377, 1.1690889596939087, -0.10343994200229645, 0.46915268898010254, 0.6772812604904175, -0.9208194613456726, -0.12247441709041595, 1.212802529335022, 0.21694926917552948, 0.9776942729949951, -0.2738022208213806, 0.05537030100822449, -0.8719549775123596, -0.06821605563163757, -0.19198516011238098, 0.4387541711330414, 1.480666160583496, 1.1728448867797852, 0.03464701771736145, -2.12933087348938, 1.3291054964065552, -0.9452970027923584, 0.5189950466156006, -0.6429811120033264, -1.3743520975112915, -0.6061479449272156, -1.124988317489624, -0.4216744899749756, -0.15466751158237457, -1.220907211303711, -0.7253104448318481, -1.4554622173309326, 0.18004757165908813, 0.5879408121109009, 2.1309564113616943, 0.2603379786014557, 0.3092711269855499, 1.133571982383728, -0.4821767210960388, 0.005431718192994595, -0.2848764657974243, -0.4862828254699707, 0.2186731994152069, 1.453304648399353, -1.5447014570236206, -1.3504152297973633, 0.1697816699743271, -1.3743942975997925, -1.2505594491958618, -0.08163371682167053, -0.6160304546356201, 0.5632860064506531, -1.3678009510040283, -0.606448233127594, 1.443547010421753, 0.6068165302276611, -3.55537486076355, 0.6800565719604492, -0.3167724907398224, 0.5166568160057068, 0.17592602968215942, -2.8424506187438965, 1.934301495552063, 0.5978597402572632, 1.7085497379302979, 2.110222339630127, 2.4649341106414795, 1.172264814376831, -0.25973019003868103, -0.410966694355011, 1.0563842058181763, -0.3049902021884918, 0.39037519693374634, -0.7033082842826843, 0.13080070912837982, -1.8120687007904053, -1.3325623273849487, -0.45409801602363586, -0.048850081861019135, -1.1820766925811768, -0.7362496852874756, -1.775316834449768, 1.2422564029693604, -0.7595154643058777, -1.922231674194336, 0.7073236703872681, 2.2605905532836914, 0.2519476115703583, 0.5262896418571472, 2.6424832344055176, 0.9247539043426514, 0.42447420954704285, 0.40138405561447144, -0.4492377042770386, -0.8058159351348877, 0.17152833938598633, -0.9966637492179871, -0.052105292677879333, -0.005634372588247061, -0.6954107284545898, -1.3542569875717163, 0.2861858606338501, -0.23888322710990906, -0.44419994950294495, 2.5330262184143066, -0.5930159687995911, -1.361369252204895, 0.32347166538238525, 0.7333517670631409, 2.4532034397125244, -0.0799422487616539, -0.12831570208072662, -1.81475830078125, -1.1742877960205078, -0.6683666110038757, -0.8978999257087708, 1.688469648361206, 0.6506508588790894, -1.7861560583114624, 0.35975199937820435, -0.18413859605789185, 0.13625440001487732, -0.627619206905365, 0.5142756700515747, 1.6465189456939697, 3.5306272506713867, 0.30679017305374146, -2.3254120349884033, 5.66782808303833, 0.06866803020238876, -1.8490585088729858, -0.32397764921188354, 0.7876318097114563, 2.592764139175415, -1.583404541015625, 0.44732680916786194, 0.11261478066444397, 0.9841850399971008, -2.098803997039795, -1.154779314994812, 0.761451005935669, 0.9219020009040833, 1.0095198154449463, 0.9458909034729004, -0.7870925068855286, -0.009385393932461739, -0.8580485582351685, -1.5734823942184448, -0.28797388076782227, 0.21141637861728668, 0.5276493430137634, -0.5387971997261047, 0.6115869283676147, 0.7321942448616028, 0.13199684023857117, 0.23573143780231476, 1.1368796825408936, 0.86569744348526, 2.1956422328948975, -0.6132652163505554, 1.6986109018325806, 0.04537703096866608, -0.9875549077987671, -0.07809349149465561, -1.007053017616272, -1.1600245237350464, 0.05101862922310829, 0.30694517493247986, 0.30190303921699524, 0.6134477257728577, 0.3784194588661194, 0.8690261840820312, 1.6746771335601807, -0.5565372109413147, -0.6757686138153076, 0.2234286516904831, 0.6996964812278748, -0.15213987231254578, 0.3642244040966034, 1.8162078857421875, -0.9228861331939697, 0.9547094106674194, 0.8881691694259644, -1.9715707302093506, 0.4207252264022827, -2.0505363941192627, -1.476912021636963, 0.27522969245910645, -1.2165052890777588, -0.7601301074028015, 1.3220300674438477, 1.0977057218551636, 0.15097220242023468, -0.2935353219509125, -1.1858482360839844, 0.7201405167579651, -0.4518771171569824, 1.0263643264770508, 0.11877082288265228, -0.08325488865375519, 0.533410906791687, -1.7733317613601685, 0.17177532613277435, 0.8895424008369446, -0.7891607284545898, -2.068913698196411, 1.7229793071746826, -0.11285923421382904, 0.7952402234077454, -0.10190329700708389, -1.780307412147522, -0.14850777387619019, -0.7082232236862183, -0.393072247505188, 0.8537764549255371, 1.9581069946289062, -0.004729109816253185, 0.01472832728177309, -0.7642340660095215, 1.3042718172073364, -0.9686558842658997, 0.9102286100387573, 1.3907831907272339, 1.6670446395874023, -0.7587276101112366, -0.21647627651691437, -1.27824866771698, 0.08190469443798065, 1.1505215167999268, -0.5959569215774536, 0.4287496507167816, 1.7633098363876343, 1.0946612358093262, 0.49460655450820923, -0.5805022716522217, -0.03832640126347542, -0.10964610427618027, -0.039654314517974854, 0.870427131652832, -0.25952696800231934, 0.9319950938224792, 1.6560300588607788, -3.9783575534820557, -0.05233611911535263, -0.39963918924331665, -0.4131673574447632, -0.20148707926273346, 0.8011397123336792, 0.6621465086936951, -3.0399978160858154, -1.2281455993652344, -0.9480983018875122, 0.48829755187034607, 0.775945246219635, -1.7521167993545532, -0.4457078278064728, 1.541290521621704, 0.6268720030784607, -0.9586774706840515, 0.25539928674697876, -1.1546826362609863, 0.9988343119621277, 0.028861261904239655, 1.2491247653961182, 1.299005150794983, 0.9799702167510986, 0.39541223645210266, 0.3784988522529602, 2.545836925506592, -0.8136555552482605, 1.0845779180526733, -0.6337446570396423, 2.415020704269409, 0.7290043234825134, 1.3579957485198975, -0.8227953314781189, 1.7049939632415771, 0.7890401482582092, -0.49144160747528076, 0.5576284527778625, -0.7442083358764648, -0.3810206651687622, 1.2724196910858154, 0.23345403373241425, -1.002681016921997, -0.3001021444797516, 1.3566659688949585, -0.5736663937568665, 0.10174994170665741, 0.05636877194046974, 0.39443689584732056, 0.033238351345062256, -1.8893957138061523, 0.049887944012880325, 0.2136702984571457, -0.4758375287055969, 0.40182697772979736, -0.07946741580963135, 0.3289596438407898, -2.9350621700286865, -1.1589385271072388, -0.8895956873893738, 0.4077507555484772, 0.06711243093013763, -3.0500972270965576, 0.4378211796283722, -1.0983201265335083, -0.3302128314971924, -2.0331108570098877, -0.8500672578811646, -0.09089633077383041, 0.058655932545661926, -1.5273798704147339, -2.1548662185668945, 1.4757522344589233, -0.4873839318752289, -0.42624977231025696, 0.4284048080444336, 0.4694344401359558, -0.5660344362258911, 0.27342164516448975, -1.5652188062667847, -0.9691106677055359, 1.6648308038711548, 0.7257683873176575, -0.6940887570381165, 1.1740951538085938, 0.0717167854309082, 2.147505283355713, -1.33943510055542, -0.23742929100990295, 1.5540844202041626, 0.53904789686203, 0.08008170127868652, -0.8907880187034607, -0.5699310898780823, -0.7341653108596802, 0.20251616835594177, -1.4321938753128052, 0.24385902285575867, 1.1057376861572266, -1.752776861190796, -1.2197519540786743, -1.2054235935211182, -2.0791125297546387, -1.4338659048080444, 0.7412952184677124, 0.5840184092521667, -0.8908865451812744, -0.4338180422782898, -2.0897815227508545, 0.10918019711971283, -0.7570163607597351, 0.3152976930141449, 1.6054037809371948, 3.3678975105285645, 1.0291696786880493, -0.3893040418624878, -0.5733335614204407, 0.21136707067489624, 0.19187550246715546, -0.8226287364959717, 1.2201296091079712, -2.1155080795288086, -0.21759164333343506, 0.07858044654130936, -1.2612978219985962, -1.3223563432693481, -0.772811770439148, 2.2174928188323975, 1.9765962362289429, -1.4131436347961426, -0.6278047561645508, 1.0233526229858398, -0.35748934745788574, -1.4454771280288696, 0.7521849870681763, -0.4448480010032654, -1.0560572147369385, 1.0125538110733032, 0.7068530321121216, 0.7841304540634155, -0.09418343007564545, -0.6311972141265869, 0.02200370281934738, 0.621896505355835, 1.1334943771362305, -2.5041613578796387, -0.3278559148311615, 1.4941039085388184, 0.40511393547058105, -0.9348725080490112, -0.31308960914611816, 2.145861864089966, 0.2717622220516205, 0.8214585185050964, -1.2210935354232788, 1.844550371170044, 0.5629890561103821, -0.43623781204223633, 1.1287091970443726, 1.9894909858703613, 0.11178211122751236, 0.9683500528335571, -0.5056583285331726, 0.05791044980287552, 0.12699291110038757, 0.12270139157772064, 2.015866279602051, 0.005398899782449007, -0.35002943873405457, 1.1573494672775269, 0.523417055606842, -1.4288545846939087, -1.2238836288452148, -1.5164622068405151, -0.3153087794780731, -1.436619520187378, -0.5331302285194397, 0.637260377407074, 0.5407271981239319, -0.39856117963790894, -0.9558438658714294, -0.9962703585624695, -0.2867629826068878, -0.8861436247825623, 1.7947380542755127, -1.2196016311645508, 1.6623975038528442, 0.1321093887090683, -1.2425278425216675, -0.5616293549537659, -1.00057852268219, 2.1755096912384033, -0.43419569730758667, 1.6970324516296387, 0.2883619964122772, -0.8315949440002441, 0.1168961226940155, -1.435927152633667, -0.8152343034744263, 1.0223966836929321, -1.201563835144043, -4.576572418212891, 0.12326008081436157, -0.9687467813491821, -1.1807663440704346, -2.3227715492248535, -0.6160868406295776, -2.1992459297180176, 1.1330646276474, -1.1717530488967896, -1.6694926023483276, -0.1568141132593155, 1.86684250831604, -0.9101158976554871, -1.8297736644744873, -0.4739183485507965, -1.6375294923782349, 2.078448534011841, -1.0559351444244385, -3.036759376525879, -0.3570570647716522, -1.0014989376068115, -0.20469219982624054, 1.2208061218261719, 1.0647602081298828, -0.5665226578712463, 3.629319667816162, 0.41066375374794006, 3.4938619136810303, 1.0168339014053345, 0.7922152280807495, -1.2958086729049683, -0.6018487811088562, -0.25427761673927307, -0.30984020233154297, 1.4170398712158203, 0.12417089939117432, 2.5346856117248535, 0.6929503679275513, 1.4002596139907837, 1.7187341451644897, -0.12474063038825989, -0.6034557223320007, 1.1340513229370117, -0.406726598739624, 0.6989826560020447, 0.38001877069473267, 0.72823166847229, -0.20287975668907166, 1.223062515258789, 1.2957690954208374, 2.5065202713012695, -0.038991693407297134, -0.1762339323759079, -0.9306122660636902, 1.6339150667190552, -1.2192964553833008, -0.5525882840156555, 1.0211365222930908, 0.7179843187332153, -0.10462075471878052, 1.1384401321411133, 1.8902853727340698, -0.9081380367279053, 0.1559951901435852, -1.692693829536438, -1.5845937728881836, -0.05665544793009758, -0.4705516993999481, 1.7070945501327515, 1.2261683940887451, -0.31657975912094116, -0.4428073465824127, -0.4361644983291626, 1.6553292274475098, 1.0730377435684204, 0.41127288341522217, -1.1040656566619873, 0.6516175270080566, -0.7295853495597839, -0.8160379528999329, 0.6715840697288513, 1.4327118396759033, -1.1232383251190186, -0.30075573921203613, 0.46891623735427856, 2.6533737182617188, 0.024896694347262383, 0.26940619945526123, -0.3732120990753174, -0.09108052402734756, -1.1092764139175415, 0.13357973098754883, -0.7557004690170288, -0.41944658756256104, 0.318857878446579, 0.755761444568634, -0.6168466806411743, 2.458892583847046, 0.1425238400697708, 1.1061031818389893, -0.37816575169563293, -0.9338823556900024, -0.06843240559101105, -0.9857388734817505, 0.6522310376167297, -1.8074395656585693, 0.36431825160980225, -1.6977341175079346, 0.8062208890914917, 1.890913486480713, 0.41531047224998474, -0.33974090218544006, -0.8411772847175598, -0.18934394419193268, 1.8145952224731445, -2.4242682456970215, -1.459102988243103, 1.1252561807632446, 0.6712928414344788, 0.6805633902549744, -1.2508337497711182, 0.6980308890342712, 0.2244257777929306, -1.5959521532058716, -0.1427992731332779, -0.25788718461990356, 1.7008132934570312, 0.43730995059013367, 0.5585684180259705, -0.7365202903747559, -1.9040342569351196, -0.3696852922439575, -0.07319577038288116, 1.0936815738677979, 0.9186830520629883, 1.5111664533615112, 1.7242950201034546, 2.255995988845825, -0.24301069974899292, 0.48337242007255554, 0.18106970191001892, 0.7289482355117798, 0.17799854278564453, -0.05487207695841789, -0.6266309022903442, -0.9526889324188232, -0.9719439744949341, -5.365569591522217, 1.0868366956710815, 1.3846880197525024, 0.7252110242843628, -0.18636974692344666, -0.24770641326904297, -0.18448655307292938, -2.368692398071289, -0.9364539384841919, -0.25291240215301514, -1.3329951763153076, 1.206251621246338, 1.2820242643356323, -0.2806427776813507, -0.8152094483375549, 0.09828636050224304, 1.323858380317688, 0.9702240824699402, 0.41342824697494507, -1.468760371208191, -1.314807415008545, -0.2602055072784424, 0.4903044104576111, -2.8911993503570557, 0.7195784449577332, -0.39719730615615845, -0.18026813864707947, 1.2857232093811035, 0.6434314846992493, -0.26736751198768616, 1.723885416984558, 0.17223870754241943, 1.5073626041412354, -0.3132191300392151, -0.7933035492897034, -0.027386829257011414, 0.371181845664978, 0.20647452771663666, 0.801419734954834, 1.0539473295211792, -1.559119701385498, -0.6904587745666504, -0.31644436717033386, 0.10372668504714966, -0.39853087067604065, -0.4249415993690491, -0.08421067893505096, 0.4556313753128052, 1.079956293106079, -0.9575961828231812, -2.83273983001709, -1.219688892364502, -0.06913143396377563, -5.1352219581604, -0.7862509489059448, -1.344568133354187, -0.21717557311058044, 0.0812382847070694, -1.6223338842391968, -0.11848697811365128, 1.4473354816436768, -1.1862537860870361, -1.0266728401184082, 0.010097034275531769, 1.071507453918457, 0.08284241706132889, 0.14348864555358887, -0.2896728515625, -1.9309585094451904, 0.6712353825569153, -2.1891722679138184, 2.017864942550659, -0.010664403438568115, 0.14723323285579681, -0.39580270648002625, 0.6754334568977356, -0.4616096317768097, 0.14950796961784363, -0.15492965281009674, -0.5268170833587646, 0.6093330383300781, -0.7512282729148865, -0.9248431324958801, -0.17124100029468536, 0.7890377640724182, 0.6388524174690247, -2.6870532035827637, 2.3500428199768066, 2.7369351387023926, 0.6385066509246826, -0.10861345380544662, 0.47104763984680176, -0.3476681709289551, -0.3912145495414734, -0.053814634680747986, 0.11334793269634247, -0.9905673265457153, 0.1762138456106186, -2.105621099472046, 0.7925429940223694, -0.04662153869867325, -0.09735759347677231, 0.2975177466869354, -0.5815366506576538, -1.2133547067642212, -1.7181720733642578, 0.4753974676132202, 0.0808500200510025, 1.3429497480392456, 0.5658619999885559, 0.6430619359016418, 0.2377920001745224, 0.027724193409085274, -0.38658592104911804, 1.09468674659729, 0.022412439808249474, 1.0868088006973267, 1.3744572401046753, -0.7318962812423706, 0.4355296492576599, 0.943031907081604, 1.9187633991241455, 2.3653581142425537, -0.3438974916934967, 0.7376349568367004, -1.4072799682617188, 0.46009454131126404, -0.38767966628074646, -0.27747559547424316, -0.1930069774389267, -0.9755553603172302, 0.11107908934354782, 0.7764224410057068, -1.9832584857940674, -0.9143242835998535, -0.06754657626152039, -0.045556843280792236, -2.002258539199829, 0.6596161723136902, 1.093137502670288, -0.37651199102401733, -0.4334995150566101, 0.9280827045440674, 0.14469397068023682, 1.1795120239257812, -0.24902334809303284, 0.045476723462343216, 0.7615187764167786, -0.3605820834636688, 0.6943137645721436, -1.4301263093948364, -0.032285165041685104, 0.6076567769050598, 0.04330214485526085, 0.18491071462631226, -1.186514973640442, 0.5377578139305115, 0.9451528191566467, 0.2077617198228836, -1.21592378616333, 0.3471309244632721, 0.9311133623123169, -0.031072469428181648, -0.48340803384780884, -0.5190680027008057, -1.6854925155639648, -0.5275440216064453, 0.9956777095794678, 1.8246852159500122, -1.1587107181549072, -0.3617734909057617, 0.2640167772769928, -0.6512187719345093, 2.2660481929779053, 1.8700419664382935, 0.4507567882537842, 1.5972391366958618, -0.11757924407720566, 0.4615710377693176, 0.8382851481437683, 0.6783636808395386, -1.0391405820846558, -0.6359390616416931, -0.24318550527095795, 0.7935256361961365, 1.6131460666656494, -1.0161648988723755, 0.5263340473175049, -1.3308320045471191, -1.7281575202941895, -0.704335629940033, 1.0077855587005615, -1.1938259601593018, 1.1689928770065308, 0.2708398699760437, 2.1387908458709717, -0.9211075901985168, -1.962174654006958, 0.1627049446105957, 0.0950494036078453, -0.4552338123321533, -1.1138957738876343, -0.8793669939041138, 0.5108163356781006, -1.0808945894241333, 0.8596720695495605, -0.6894169449806213, 2.347797393798828, 0.09048116952180862, 0.7201135754585266, 0.6169108748435974, 0.45506489276885986, -2.1425857543945312, 1.6322115659713745, -0.4599458575248718, -0.49228405952453613, 0.8861127495765686, 1.8622196912765503, 0.5094283819198608, -0.4788426458835602, -0.5258786082267761, -1.7823809385299683, -0.17901577055454254, 0.2591533064842224, -0.4177533686161041, -1.5260809659957886, -0.979034423828125, -0.20833510160446167, -0.9541704654693604, 0.35373836755752563, -0.020128712058067322, -0.5540364384651184, -0.2181689739227295, -0.9266387820243835, -1.714384913444519, 0.5314677953720093, -0.3863259553909302, 5.063751220703125, 0.22678014636039734, -0.262852281332016, 2.869086742401123, 0.4205756187438965, 0.8878121376037598, -0.5106886625289917, -1.897331714630127, -1.7289676666259766, 0.04126931354403496, 0.7733020782470703, -0.19713838398456573, 0.4139724671840668, 1.725616455078125, 1.8642007112503052, -0.14081408083438873, -0.46096697449684143, -0.8493478894233704, 0.9900148510932922, -0.31041136384010315, 1.193366527557373, -1.678012728691101, -1.4701511859893799, 1.7127928733825684, -0.13831640779972076, 0.1491186022758484, -0.8937328457832336, 1.3914390802383423, -0.25655537843704224, 1.073940396308899, -0.30518028140068054, 0.4562370479106903, 0.672607421875, -0.2002001255750656, -0.8009520173072815, -0.4773408770561218, 0.8259692788124084, -1.619404673576355, 1.0932269096374512, -0.34169846773147583, 0.9464579224586487, -0.5704147815704346, -1.1871365308761597, -0.6263683438301086, -0.5830976963043213, -0.08898698538541794, 0.46420514583587646, 0.890923261642456, -0.18494802713394165, 0.5548846125602722, -0.4481979310512543, -0.6865315437316895, 0.2963058352470398, -1.0211983919143677, -0.3104568421840668, 0.9339863061904907, 0.38805457949638367, -0.6665626168251038, -1.7484403848648071, 1.2936362028121948, -0.4030556082725525, -0.7539618611335754, 0.17469905316829681, 0.5328199863433838, -1.1831449270248413, 0.7525746822357178, -0.4632769823074341, -1.5771037340164185, -0.3881469964981079, 1.3855177164077759, 0.5843231081962585, -0.011489511467516422, 0.1942916214466095, -0.07073962688446045, -0.713753879070282, 0.40204349160194397, -0.1553383767604828, -1.378898024559021, 1.5379952192306519, -0.09437404572963715, 1.19918692111969, -0.4566217362880707, -0.17698045074939728, 0.1848151534795761, -0.5274324417114258, 0.22686506807804108, -0.54227614402771, -1.7103651762008667, 1.3333277702331543, 0.3541317880153656, 0.38645192980766296, 0.3385314345359802, 0.5316886901855469, -0.33387672901153564, 1.3350239992141724, 0.2984113395214081, 0.6667865514755249, 0.5174212455749512, -0.35142889618873596, 0.05407225340604782, 0.20732949674129486, -2.143418312072754, -2.40152645111084, 0.544480562210083, 0.2735079824924469, 1.0653938055038452, 0.5454756021499634, -3.809938430786133, 1.3668920993804932, -0.18790708482265472, -0.6467604637145996, -0.7983043789863586, -0.4102362394332886, -0.8554783463478088, 1.406027913093567, 0.03601374849677086, -0.3404277563095093, 0.6969571113586426, -0.29023483395576477, -0.278060644865036, 0.8022031784057617, 0.2382769137620926, 1.459484338760376, -0.6661571264266968, 0.7167996168136597, -1.5642902851104736, 0.240248903632164, 1.803597092628479, -0.7625988125801086, 1.2015897035598755, -0.5113502740859985, -0.10265414416790009, -1.291350245475769, -0.8875960111618042, 1.0336229801177979, -0.1949157565832138, 0.4413243532180786, 0.5952431559562683, 0.3680347204208374, -0.7185171842575073, -0.13600648939609528, -0.29599475860595703, 1.1092694997787476, -0.7886794209480286, 0.07877198606729507, 1.1021233797073364, -1.8648775815963745, 0.10571010410785675, 0.958071768283844, -1.3490862846374512, 1.4406616687774658, -0.09497468918561935, 0.4291427433490753, 0.8125904202461243, 1.3080710172653198, -0.7619430422782898, 0.18317878246307373, 0.7478725910186768, 0.07775179296731949, -1.8916021585464478, -2.391003131866455, -0.16344578564167023, 0.748140811920166, 1.5319370031356812, 1.7897381782531738, 0.3170207440853119, 1.903025507926941, 0.7427331805229187, 0.5609701871871948, -1.1940834522247314, -0.726371169090271, -1.3231393098831177, 2.2336931228637695, -0.6093462109565735, -2.98012113571167, 1.0353821516036987, 0.6350229978561401, -0.16519363224506378, 0.4092809557914734, -1.7545883655548096, -0.11545154452323914, 2.2166545391082764, 0.04411093518137932, -1.7661304473876953, -2.368497610092163, -0.8803841471672058, 0.8894960284233093, -0.3606656491756439, -0.46432873606681824, -0.8316271901130676, 0.9811064004898071, 1.149061679840088, -1.2615962028503418, -1.2993687391281128, 0.155769944190979, -0.6835947632789612, 1.2468066215515137, -0.42691758275032043, -0.2459997683763504, 0.04337785020470619, -0.28209155797958374, 0.6625828146934509, -0.0562194362282753, 1.2752002477645874, 0.5944263339042664, -0.9563129544258118, 0.3772636950016022, 0.34999504685401917, 1.4225435256958008, -0.981197714805603, -0.6483834981918335, -0.6822648644447327, 0.8229963183403015, 1.592727780342102, 0.9465079307556152, 0.9707575440406799, -2.0313241481781006, 0.14244085550308228, 0.17967243492603302, -0.9468193054199219, 1.4360630512237549, -0.3884754776954651, -0.15175725519657135, 0.6735648512840271, -0.8823621869087219, -0.42255496978759766, 0.1931266486644745, -1.2269757986068726, -0.9772740602493286, -0.08430574089288712, 1.8324551582336426, 0.6960350871086121, -0.6578008532524109, -1.4050111770629883, 0.14333920180797577, 0.9100018739700317, 1.5275120735168457, -1.7053196430206299, 0.09019837528467178, -0.7814130783081055, -0.47474274039268494, 0.2650811970233917, -0.2690514326095581, 2.3244755268096924, 1.2322402000427246, -0.8384011387825012, -1.9226030111312866, -0.5085896253585815, 0.4418678283691406, 0.47715315222740173, 0.39102646708488464, -0.8957337737083435, 0.6675345301628113, 0.11687757819890976, -0.39829620718955994, -1.1858723163604736, -0.2420654147863388, 0.5813144445419312, -0.9648045897483826, 0.7612326145172119, -0.4536987543106079, 0.6916894316673279, -1.3421292304992676, -0.462801456451416, -1.7419843673706055, 0.34195372462272644, 1.8126693964004517, -1.1827473640441895, 0.424064576625824, -1.2967699766159058, -1.2690844535827637, -0.038091763854026794, 2.5800087451934814, 0.944311261177063, 0.14745251834392548, -0.8592954874038696, 0.7310591340065002, -0.9737454652786255, 0.9340552687644958, 0.0033666130620986223, -0.5727726221084595, 1.003236174583435, 0.4055235981941223, 2.032198429107666, -1.3523820638656616, -1.4475315809249878, 0.5783364772796631, 0.050668176263570786, -1.345272183418274, 0.11927986890077591, 1.055626392364502, 1.8005313873291016, 1.3142576217651367, -0.5859289765357971, -0.45881912112236023, 1.75102698802948, -0.6187845468521118, 0.3707292377948761, 0.3473500907421112, -2.2356436252593994, 0.275532603263855, 1.6056199073791504, -1.0330487489700317, 0.03177648410201073, 0.9236984252929688, 1.6071723699569702, 0.035536110401153564, 0.47229984402656555, 0.7846123576164246, -0.4549621641635895, 0.6562485098838806, -1.4710761308670044, 1.9479930400848389, 1.0193549394607544, -0.3508604168891907, -1.4390363693237305, 1.1536699533462524, 0.15485545992851257, 1.5938040018081665, -1.5184435844421387, -0.16816513240337372, -1.0537381172180176, 1.2023268938064575, -1.4081389904022217, 4.45023775100708, -0.934660017490387, 1.2406572103500366, -1.710037350654602, 0.38362202048301697, 0.7490648031234741, 0.10709893703460693, -0.38497480750083923, 1.1712125539779663, 0.7761016488075256, -0.07529023289680481, -1.3460386991500854, -0.3687780499458313, 0.43025434017181396, 1.6625734567642212, -0.2732877731323242, -1.13008451461792, -0.28735339641571045, -0.351082980632782, -1.1725828647613525, -2.4060022830963135, 1.0864295959472656, 0.7974997758865356, 0.9816272258758545, 1.4364902973175049, 0.6853913068771362, -0.9246468544006348, 1.3724603652954102, 0.6886865496635437, 0.4485724866390228, 0.29938045144081116, 0.25413569808006287, -0.3020130693912506, 0.8710833787918091, 0.2018548846244812, 1.3915214538574219, -0.021525247022509575, 0.2696515917778015, 0.48707565665245056, -0.812926709651947, -0.5481247901916504, 0.45377862453460693, -0.5770244002342224, 0.376587837934494, 2.722252130508423, -1.336781620979309, 0.9590557813644409, 0.8766461610794067, -0.3795398771762848, 2.599395990371704, 1.006022572517395, -1.2528496980667114, -0.17171576619148254, 2.8199574947357178, -0.7691469788551331, 1.0298750400543213, 0.5427713394165039, -0.29765307903289795, 1.6536530256271362, 0.6595377922058105, -0.4602827727794647, 1.092271327972412, 0.24642477929592133, -0.6995567679405212, 0.9301406741142273, 1.9597723484039307, -2.1039280891418457, 0.46435546875, -1.0452983379364014, -0.11919096857309341, -1.8597439527511597, 0.3998560905456543, 1.4825960397720337, -0.03595923259854317, 0.07040435075759888, 1.2785290479660034, 0.5225769281387329, -0.5477554798126221, 1.0132536888122559, 0.28393444418907166, -1.304807424545288, -0.22691014409065247, -0.10035088658332825, -1.2982447147369385, 0.5517842173576355, -0.09860510379076004, -0.50215744972229, 2.678603172302246, 0.2192768007516861, 1.6600136756896973, 0.4791076183319092, -0.30167967081069946, 1.052679181098938, 0.917363703250885, 0.06161622330546379, -0.7817452549934387, -0.3372204601764679, -1.938130497932434, -1.3456531763076782, 1.6118067502975464, -1.373962163925171, 0.9626410007476807, -2.2814671993255615, -0.16582268476486206, 0.17157572507858276, -0.09329783916473389, -0.5615853071212769, 0.38309183716773987, -1.3946870565414429, 1.455332636833191, 1.3213331699371338, -0.342104971408844, 0.6295957565307617, 0.6168071031570435, -1.3850681781768799, -0.40843793749809265, 2.10193133354187, 1.308969259262085, 1.3342608213424683, -0.11378708481788635, 0.3343682587146759, -1.3455884456634521, -0.2613583207130432, -0.09449667483568192, -0.4088842272758484, -0.43082430958747864, 0.7633748054504395, 0.27128368616104126, 1.1447713375091553, -1.1975408792495728, -1.6384345293045044, -0.40583088994026184, 0.07026170939207077, -0.6788767576217651, 0.3204025328159332, -2.353562593460083, -0.24283969402313232, -0.06821220368146896, 1.538472294807434, 0.13376405835151672, -0.7911478281021118, 0.7973702549934387, -0.6859928369522095, -0.20257072150707245, 1.0625237226486206, 1.2180088758468628, 0.4202701449394226, 0.014905501157045364, 0.30595657229423523, 1.6823077201843262, 0.4587283432483673, -0.2502537667751312, -0.24125154316425323, 0.5457378029823303, 0.2186788022518158, -0.06776216626167297, 0.3693813979625702, 3.0939817428588867, -0.5471578240394592, 0.7769420742988586, 0.9252727031707764, -0.3128696084022522, -0.7260084748268127, -0.8054773807525635, 1.619175672531128, -0.867920994758606, 0.6180009245872498, 1.4990918636322021, 0.06804749369621277, 1.2359974384307861, -0.055460359901189804, 2.247371196746826, -0.29353490471839905, 0.6970447897911072, 0.20579254627227783, 2.092158079147339, -0.4029512405395508, -2.223621368408203, -0.37378546595573425, 2.010382890701294, 0.02367810346186161, -0.032547540962696075, -0.8835751414299011, 0.22496014833450317, -1.07090163230896, -0.9764360785484314, -3.1100199222564697, 0.3374684154987335, 1.095337152481079, -0.10852470248937607, 0.7751117944717407, -1.5970895290374756, 1.6862804889678955, -1.8167800903320312, -0.5527069568634033, -1.9368975162506104, 0.00984608381986618, 0.16423270106315613, 1.1716889142990112, 0.15162236988544464, 0.03864515572786331, -0.3522260785102844, 0.2717590928077698, 1.3141751289367676, 0.19820575416088104, 1.5704200267791748, 0.9067113399505615, -0.8667936325073242, 0.7036771774291992, 0.408005028963089, -0.08118331432342529, 1.052250623703003, 0.19432896375656128, 0.21872514486312866, 0.8815085291862488, -0.43560919165611267, -1.3185282945632935, 0.7686471343040466, 0.888715386390686, 0.06770183891057968, 0.00600831676274538, 0.9181489944458008, 0.2056282013654709, -1.3395017385482788, 1.1827075481414795, 0.18733230233192444, 1.0576592683792114, 1.3177722692489624, -1.215716004371643, 0.8288293480873108, 0.6527824997901917, 0.5109286904335022, 0.10516000539064407, 1.553834319114685, 0.13581551611423492, 0.21668189764022827, 0.7178095579147339, -0.4471808075904846, -0.32226279377937317, 1.1473729610443115, 1.1927950382232666, -2.144613742828369, 0.7665403485298157, 1.5447044372558594, -0.09101144969463348, 0.8880476951599121, -0.0651455894112587, 1.3903191089630127, 0.2728159427642822, 0.946292519569397, 0.11349012702703476, 0.6417002081871033, 1.0087461471557617, -1.5080602169036865, 1.2119089365005493, 0.6974173188209534, 0.05704190209507942, 1.2845710515975952, -1.1534874439239502, -0.16539601981639862, 0.4632440507411957, 0.31995725631713867, 0.20680001378059387, -1.317483901977539, -1.002992868423462, 1.3954728841781616, -0.40269899368286133, 1.1824203729629517, 0.9290528893470764, 0.05345574766397476, -1.3870513439178467, -0.31724610924720764, 0.003360999980941415, -0.5655406713485718, -1.262547492980957, -0.6892083883285522, -0.013680498115718365, -0.9971417188644409, -1.6974844932556152, -1.534899353981018, -0.6274785995483398, -2.4628028869628906, 0.4089762270450592, 1.4564648866653442, 2.3958418369293213, -1.8966631889343262, 0.8049674034118652, 0.5483586192131042, 0.02793111279606819, 1.3917460441589355, 0.4329898953437805, 1.3445416688919067, 2.565514326095581, 0.8019831776618958, 0.08283072710037231, 1.444972276687622, -0.9912630319595337, -0.14561964571475983, -1.1138684749603271, -0.02355946972966194, -1.6253629922866821, -0.7180989384651184, -1.4820071458816528, -0.3990137577056885, -0.7859840989112854, -0.10988111793994904, 1.1315103769302368, -1.276066541671753, -0.15967881679534912, 1.7027240991592407, -0.5975544452667236, -0.4606564939022064, -0.49828705191612244, -0.24023306369781494, -1.2565479278564453, -0.4669572710990906, 0.5578574538230896, -1.047023057937622, -1.515228271484375, -0.4723411798477173, 1.5094741582870483, 1.5394287109375, -0.9457025527954102, -1.067751169204712, -0.08809521794319153, -0.7453733682632446, -0.8412367701530457, 1.5402429103851318, 0.8702358603477478, -0.7532011270523071, 0.6594656705856323, 1.7538617849349976, -0.40960997343063354, 0.2721245586872101, 0.3300169110298157, 0.7698466181755066, -0.5730629563331604, -0.6278852224349976, 0.4222230017185211, -1.5032299757003784, 0.15380792319774628, -0.3639902174472809, 2.4838345050811768, 1.2292736768722534, -0.3628005087375641, -0.41655516624450684, 0.29880884289741516, -0.5581997036933899, -0.980165421962738, -0.517394483089447, -2.0796236991882324, 0.7382667064666748, 0.1920417845249176, -0.1699713170528412, 0.12123429775238037, -0.7080588936805725, 0.9163708090782166, -0.09569180011749268, 0.022447803989052773, -0.8285136222839355, 0.7857940196990967, -1.8306740522384644, -3.16143536567688, 0.1578119993209839, 0.965684711933136, -1.1044912338256836, 0.8420507311820984, 2.712552547454834, -0.1373884677886963, 0.8322644829750061, -0.604379415512085, 0.025483079254627228, -0.4021773934364319, 1.0926728248596191, 0.48565834760665894, 1.3001095056533813, -0.6747169494628906, 0.7547209858894348, -0.5974134206771851, 0.4333666265010834, -0.03130440041422844, -0.26801034808158875, 0.9387853145599365, -1.9990637302398682, -0.3071124851703644, -0.0320502370595932, -0.7862548828125, 2.163693428039551, -2.0458498001098633, -0.877183198928833, -0.14140203595161438, 2.741060972213745, -0.5744778513908386, 1.9629567861557007, 0.29778072237968445, 0.48224201798439026, -0.599865198135376, 0.26124173402786255, 0.29952338337898254, 1.5433616638183594, 0.0629357099533081, 0.1896980106830597, -1.1199688911437988, 1.1342231035232544, -1.0404579639434814, -0.045887358486652374, -0.2145300805568695, -0.004418264143168926, 0.5088541507720947, -0.5111268758773804, -1.865917444229126, -0.7750115394592285, 1.0943899154663086, 0.042996007949113846, -1.5877941846847534, 0.4978092908859253, 1.920859932899475, -0.19736529886722565, 0.34627842903137207, 0.6925984025001526, 0.4474102854728699, 0.49408113956451416, -0.4236809015274048, 1.0775634050369263, -0.2346191555261612, 0.3135434091091156, 1.7259994745254517, -0.07675348967313766, 1.3932123184204102, 3.093411922454834, -1.059804916381836, 0.8463006019592285, -0.6980856657028198, -1.265904426574707, 2.4349660873413086, -0.4304540455341339, 0.36587345600128174, 0.9539275169372559, 0.6497138738632202, -1.4864082336425781, -1.7395110130310059, -2.0720012187957764, -0.6552324295043945, 0.6367698311805725, 1.0661776065826416, 0.6815173029899597, -1.7547932863235474, -1.0382485389709473, -0.16837814450263977, 1.177322506904602, 0.4179031550884247, -0.1878644824028015, -1.2555853128433228, 0.2706548869609833, -0.3127058744430542, 1.5459157228469849, -0.9939788579940796, 2.261122941970825, 1.6450861692428589, 0.3427158296108246, -0.9708268642425537, -0.3755829632282257, 1.0751628875732422, 1.8929407596588135, 0.7748454213142395, -0.9319918751716614, -0.6555737257003784, 0.4240409731864929, 0.6905285716056824, -0.026056263595819473, 0.7730779051780701, -2.0821475982666016, 0.06186005473136902, -0.4756685197353363, 0.43158093094825745, -0.029053784906864166, -0.28028589487075806, 0.20237918198108673, -0.32695314288139343, 0.1078081950545311, -0.7202011346817017, 0.5051103830337524, -1.7595252990722656, -0.9588852524757385, 1.2174253463745117, -1.7406961917877197, -0.9630842804908752, -0.7345975637435913, -0.36041563749313354, -1.1401909589767456, 0.2517213225364685, 1.4442483186721802, 0.744284987449646, 1.6906650066375732, -1.1765800714492798, 1.9878040552139282, -0.2795201241970062, -0.9187508821487427, 0.9795004725456238, -0.9528474807739258, -0.10279913246631622, -0.21618357300758362, 1.7935806512832642, -0.07653357088565826, -1.1513093709945679, -0.622367799282074, 0.18704654276371002, -0.5623005628585815, 0.3162189722061157, -0.014233623631298542, -1.3464628458023071, 1.600023627281189, 0.6324451565742493, 0.07035932689905167, -0.17235134541988373, 1.2747679948806763, 0.769943356513977, -0.9073511958122253, -0.36585673689842224, -0.8952293992042542, 0.14941206574440002, -1.6643203496932983, -0.6286594867706299, -0.5030408501625061, -0.6043803095817566, -0.563330352306366, 0.20052272081375122, -0.8003237843513489, 0.8933444023132324, 0.15094055235385895, 1.2097983360290527, -2.29616117477417, 0.4300495982170105, 0.785442590713501, 1.3268249034881592, -0.17365163564682007, -2.279106378555298, -1.3883581161499023, -0.01731434091925621, 0.6396061182022095, 1.0316296815872192, 1.1356178522109985, 1.3007344007492065, 2.035425901412964, 0.024668220430612564, 1.4233003854751587, -1.8298646211624146, 0.39429864287376404, 0.5284878015518188, -0.9126739501953125, 1.02884042263031, -1.3293416500091553, -0.04956648498773575, -0.17606186866760254, 0.5702002644538879, 0.7570909261703491, 0.01759483478963375, -1.1018779277801514, 0.06869005411863327, 0.7397280931472778, 0.08491063117980957, 1.3096240758895874, 0.7574928402900696, 0.6136136651039124, 0.619525671005249, -0.4451301693916321, -0.797400176525116, -0.5927930474281311, 1.1865580081939697, -1.9312241077423096, 0.9842230677604675, -0.9229553937911987, 0.8188202977180481, 0.6025241613388062, 0.602641224861145, -1.2741143703460693, -0.19613495469093323, -0.07055815309286118, 0.2221410870552063, 0.040457163006067276, -1.2956472635269165, -1.3966975212097168, -0.37894150614738464, 0.6468443274497986, -1.295080542564392, 0.1830379068851471, -0.3397437036037445, 0.8488261699676514, 0.4374510645866394, 0.026820503175258636, -0.20547135174274445, 0.5442807674407959, 1.0659996271133423, 0.37078943848609924, -1.0301162004470825, -1.568084478378296, 0.4772208034992218, 0.7610529065132141, -0.26226311922073364, 2.759986639022827, -2.237426519393921, -1.3927329778671265, -0.25067052245140076, -0.034761641174554825, -1.6483365297317505, 0.3916987478733063, 0.4776897132396698, 0.060378547757864, -0.2563505172729492, -0.05348607152700424, 0.15754449367523193, 0.29312655329704285, -1.3077884912490845, -1.2057512998580933, -2.0031352043151855, 1.2639356851577759, 0.30329927802085876, -1.7382090091705322, 1.2997829914093018, -0.7712218761444092, -2.534291982650757, -0.9273201823234558, 1.1417112350463867, 0.4346247613430023, 0.313414990901947, 1.4013580083847046, -0.33611539006233215, -0.6323506236076355, 0.5600084662437439, 0.04663786664605141, -1.3558738231658936, -1.2608860731124878, -1.4690542221069336, -2.357400417327881, 0.40088286995887756, 0.4500943720340729, -0.9596972465515137, 1.7256109714508057, -1.3539413213729858, 0.4143567979335785, 0.5937530994415283, -0.44048410654067993, -0.21144399046897888, 0.678516149520874, 1.4156197309494019, -0.47730782628059387, 0.7325049042701721, 0.7921350598335266, 1.4682344198226929, 0.9522017240524292, 0.8915248513221741, -1.1237623691558838, -1.742781639099121, -0.4034915268421173, -0.34888705611228943, -0.9867533445358276, 0.22715787589550018, 0.26908954977989197, -0.6980142593383789, -0.5126373767852783, 0.5481606125831604, 1.160300612449646, 0.03545679152011871, -0.7001634836196899, 0.8917142748832703, 0.008744572289288044, -1.9906197786331177, 1.7550498247146606, 1.5309398174285889, -1.0246222019195557, -0.8405205011367798, 1.449825644493103, 0.24577881395816803, -0.11463680863380432, -2.493936538696289, -0.48522642254829407, 1.8970847129821777, 0.7694624066352844, -1.1790353059768677, -0.011789977550506592, -1.1395304203033447, 0.05347800999879837, -1.1696662902832031, 0.7458067536354065, 2.3123583793640137, -0.931072473526001, 0.11655191332101822, -0.061920445412397385, -0.6007417440414429, 0.7644291520118713, -0.040669720619916916, -1.2948896884918213, -0.19696743786334991, -0.061361465603113174, 0.8523626923561096, 0.14531496167182922, -1.2310600280761719, 1.6482511758804321, 0.12839841842651367, -1.5313364267349243, 2.5933620929718018, -2.132350444793701, -0.6056895852088928, 0.9961222410202026, 0.9513058662414551, 1.8770654201507568, -1.979382872581482, -0.7869384288787842, -1.5924721956253052, 1.625808835029602, 0.2938637137413025, -0.8708399534225464, 1.7555994987487793, -0.16881264746189117, 0.8323983550071716, -0.8108518719673157, 0.1742166131734848, -1.450279951095581, 0.42231932282447815, -0.0689379870891571, -0.33100077509880066, -1.9218664169311523, 0.8077700138092041, -1.1599822044372559, 2.2854926586151123, -1.425921082496643, -0.8497033715248108, 1.7569621801376343, 0.7910576462745667, 0.6590638160705566, -2.0718295574188232, 0.022181013599038124, 1.0837903022766113, -0.10409845411777496, 1.2982795238494873, 0.8684987425804138, 0.6340055465698242, 0.6559709906578064, 0.49543875455856323, -0.7792903780937195, 1.1251435279846191, -0.4158199429512024, 0.1328325867652893, -0.056905392557382584, -0.6200520396232605, -0.5512281060218811, -0.5096279382705688, -1.8733065128326416, -1.2818721532821655, -0.21185104548931122, 0.5491910576820374, 0.35709983110427856, -1.857981562614441, -1.1611803770065308, 1.7799785137176514, -1.7085933685302734, 1.576467752456665, 2.023192882537842, 1.164253830909729, 0.10019667446613312, 0.025835122913122177, -1.959472417831421, 0.24479597806930542, 1.5978145599365234, -1.5428946018218994, 0.5645467042922974, -0.3962751030921936, 0.12275216728448868, 0.23358920216560364, 0.8720585107803345, 0.7354390025138855, -0.3454125225543976, 0.4207579791545868, 0.7065187692642212, -11.945854187011719, -1.0075725317001343, 0.5993790626525879, -0.4670860171318054, 0.6922800540924072, -0.6205817461013794, 0.29391470551490784, 1.092780351638794, -0.8538411259651184, -0.577072262763977, -0.5119575262069702, 1.231869101524353, -0.9487578868865967, 0.07447053492069244, 1.2817422151565552, 1.2125985622406006, 0.289366215467453, 0.14221985638141632, 2.8182053565979004, -0.6206324100494385, 0.13736915588378906, -1.1475833654403687, 0.32179930806159973, 0.22725021839141846, -0.47989800572395325, 0.29595547914505005, -0.28713682293891907, 0.3441757559776306, -0.36944183707237244, 0.24982571601867676, -0.18244461715221405, 0.11522049456834793, 0.8259894251823425, 5.561600685119629, 0.5185537338256836, 1.0462110042572021, -1.3385252952575684, 0.534442663192749, 1.0471980571746826, -1.068116307258606, -0.10212521255016327, -0.012793662026524544, -0.3861364424228668, -0.891900360584259, 0.9998407959938049, -0.2598210573196411, -1.5087120532989502, -2.0800435543060303, -1.3777084350585938, -0.019614025950431824, 0.05856369808316231, 0.6831764578819275, 0.34566041827201843, 0.4134461581707001, 1.3891733884811401, -4.329406261444092, -0.49874794483184814, -0.5203923583030701, 1.9965324401855469, -1.0931849479675293, 0.7987387776374817, -1.0231271982192993, -0.5418028235435486, 1.2131274938583374, 0.37594589591026306, 0.1270495355129242, -0.05322052165865898, 0.3056948482990265, -0.5737465023994446, -0.008738062344491482, -0.8499970436096191, 0.694561779499054, 0.665470540523529, -0.8186367154121399, -1.1295758485794067, 0.6096839308738708, -0.369858056306839, 0.7850576043128967, -1.7334489822387695, 0.1538904905319214, 0.40945103764533997, -0.5570874214172363, 0.43541786074638367, -0.24143436551094055, 0.20863574743270874, 0.07948099076747894, -2.378333330154419, -1.851338267326355, 0.38412243127822876, -0.6012730598449707, 0.0071675279177725315, 0.44706830382347107, -0.07799635827541351, -0.4127368927001953, -0.35872381925582886, -0.11995052546262741, 0.867996096611023, -0.8596305847167969, -0.09037737548351288, -0.3500984311103821, -0.42768704891204834, -1.6880353689193726, 0.894325852394104, 1.1847598552703857, -0.13666684925556183, 0.21860185265541077, 0.20925407111644745, -0.06655771285295486, -2.941934108734131, 0.09504181146621704, -0.6385946869850159, -0.2068842649459839, -0.6325771808624268, 0.8812488317489624, 0.8114174008369446, 0.3914714455604553, 0.6343419551849365, 0.1674172580242157, -0.16743367910385132, -1.1627123355865479, 1.0054537057876587, -3.1486947536468506, 0.9013642072677612, -0.3675318658351898, -0.9566017389297485, -1.6909769773483276, -0.05554661527276039, 2.427125930786133, 0.5935367941856384, 1.8385809659957886, -0.40316760540008545, 0.7104895114898682, -0.4275958240032196, 1.5040512084960938, -0.5121284127235413, -0.2178139090538025, -1.0740803480148315, -2.3064749240875244, -0.018717637285590172, -0.3625946640968323, -0.1779298633337021, -1.4490509033203125, -0.40781712532043457, -0.39312121272087097, 0.7145949006080627, -1.7787840366363525, -0.1434556543827057, 1.3356307744979858, -0.05563631281256676, -0.07271324843168259, -1.7995585203170776, 0.6623834371566772, 1.3964416980743408, -0.5351653099060059, -1.6168243885040283, -0.9634563326835632, -0.09034939110279083, -0.4136774241924286, -1.6029446125030518, -1.1045501232147217, -0.18372108042240143, -1.1874735355377197, -1.3124960660934448, -0.027837317436933517, 0.05416775867342949, 0.09107271581888199, -0.20220115780830383, 1.422370433807373, -0.04833460971713066, -0.2882823646068573, -6.194188594818115, -0.4343230128288269, 0.49889713525772095, 0.23748743534088135, -1.4999744892120361, 0.32817429304122925, -0.38760992884635925, -0.27874019742012024, -0.32208991050720215, 0.9930810928344727, -0.27275049686431885, -1.4475332498550415, -0.8324460387229919, 0.9939901828765869, 0.07643677294254303, 0.8802725672721863, -0.29458558559417725, 0.6873648166656494, -0.5325522422790527, -1.498213768005371, -0.25544995069503784, -0.9196691513061523, 1.047337532043457, -0.6536040306091309, 0.891549825668335, 1.1558709144592285, -2.251821517944336, -1.5003012418746948, 0.6878427267074585, -3.16349720954895, -0.26327866315841675, -1.4014275074005127, -0.06839915364980698, 1.0483505725860596, 0.33264780044555664, 0.2586204409599304, 1.5004727840423584, -1.9852741956710815, 2.166024923324585, 0.3034602403640747, 0.6640474200248718, 0.6580016016960144, 1.191989779472351, -0.052857618778944016, 0.034035950899124146, 2.406672239303589, 0.3860362768173218, 0.4291897416114807, 0.029092323035001755, -0.7900371551513672, -1.5204828977584839, 0.6590829491615295, 0.2155621200799942, 1.7391387224197388, -0.1569492369890213, -1.0838912725448608, 0.9621147513389587, -0.07909433543682098, -1.1809887886047363, -1.503542184829712, -0.20569570362567902, -1.2340255975723267, 0.44151830673217773, 1.4870450496673584, -0.6106038689613342, -0.4844466745853424, -0.3675532937049866, -0.417647123336792, 1.8071718215942383, 0.21781980991363525, 1.0461703538894653, 0.25533610582351685, -0.4426399767398834, 0.4911006987094879, -0.7634337544441223, -1.1514601707458496, 1.07571542263031, -1.724149465560913, -1.512345790863037, -0.36083677411079407, 0.9854034781455994, -0.17344214022159576, -1.5057811737060547, -2.0456454753875732, -0.034419946372509, -1.1925411224365234, -4.230465888977051, -0.07650057971477509, -0.23359011113643646, -0.2885163426399231, -0.8618913888931274, 0.931026816368103, -1.1181849241256714, 1.7122337818145752, -0.7653759121894836, -0.4960150420665741, 0.2246669977903366, -0.20168940722942352, 0.15373939275741577, -0.8237881660461426, 0.4585445821285248, 0.7195213437080383, -0.24190251529216766, 0.9471392035484314, 0.5333684682846069, 0.12813800573349, 1.3337092399597168, -1.0778568983078003, 0.848646879196167, 0.38628625869750977, -0.9636272192001343, 0.7457355260848999, -0.7806723117828369, -0.3816103935241699, 0.26415199041366577, -0.33215466141700745, -1.0700438022613525, 0.7109296321868896, -0.05922263488173485, 0.11984355747699738, -0.31847986578941345, -1.3195855617523193, -1.3788055181503296, 0.012418942525982857, -0.24962970614433289, -0.6711052060127258, -1.9064180850982666, -1.034805178642273, 0.05300820246338844, -0.5155351161956787, 0.29362767934799194, -0.6056204438209534, -0.42472726106643677, 0.11422640085220337, 2.3854827880859375, 0.345241904258728, 0.9803181886672974, 0.29044109582901, -0.47079959511756897, 0.01979001611471176, 0.5445156097412109, -1.087937593460083, -2.077986717224121, 1.587009310722351, -0.011139851063489914, -1.9174963235855103, -0.6532630920410156, 0.09921305626630783, -0.988667368888855, 0.5412673354148865, 0.10401000827550888, -0.0814778283238411, 0.678002119064331, -1.1946747303009033, -1.1326724290847778, 0.5830815434455872, 0.6655847430229187, 0.708301305770874, 0.8527626991271973, 0.8534773588180542, 0.3929925858974457, 2.1288981437683105, -0.7910933494567871, -0.3877546787261963, -0.925857663154602, 0.892656147480011, -0.11674093455076218, 0.1371011883020401, -1.1819639205932617, -0.38015228509902954, -0.3737689256668091, -5.218791961669922, 0.1643032431602478, 0.23833288252353668, -0.24118392169475555, -1.0021799802780151, 1.8438868522644043, -0.510435938835144, -1.1503781080245972, 0.28577086329460144, 0.7872819304466248, 0.9411619901657104, -0.512324869632721, -1.2788468599319458, -10.534174919128418, 0.5555298924446106, 0.45434948801994324, -0.06380701810121536, 0.7297359108924866, 0.41151419281959534, 0.4317672550678253, 0.8609061241149902, -0.10197076946496964, -1.081372618675232, 1.237015724182129, -0.8780797719955444, -0.05982115492224693, -0.7236195802688599, 0.927638590335846, -0.5742772817611694, 0.4067457318305969, -0.6909699440002441, 0.6085963249206543, -2.5666260719299316, 0.1690531075000763, 0.8410681486129761, -0.5935603380203247, -0.22403237223625183, 0.8189921379089355, -8.135085105895996, 0.5485336184501648, 2.234281063079834, 2.4780471324920654, 0.8472492694854736, -0.26369670033454895, 0.09892603754997253, -0.49266302585601807, 0.1733078807592392, -0.21388381719589233, 0.9772964119911194, -1.121654748916626, -2.823483467102051, 1.4309180974960327, -0.5090579390525818, 0.41330963373184204, 0.47138455510139465, 0.11963073164224625, -0.9643348455429077, -0.22137191891670227, 0.6593301296234131, 1.0931857824325562, 1.2856017351150513, 1.2198132276535034, -0.8488140106201172, 1.382440447807312, 0.46840453147888184, 0.1875144988298416, 0.37264543771743774, -1.3246153593063354, 0.20329411327838898, 0.9115938544273376, 1.3399461507797241, -0.8627544045448303, -0.107404425740242, -0.2563630938529968, 1.146032452583313, 0.8227183818817139, -0.5407421588897705, -1.8091381788253784, -0.09863817691802979, 1.1930168867111206, -1.4420102834701538, 1.9431079626083374, -0.3427444398403168, 5.33044958114624, 0.41187575459480286, -1.7491422891616821, -0.22674855589866638, 0.5656130313873291, 0.5671996474266052, 0.20453104376792908, -0.5792331099510193, -0.07820568233728409, 0.8382443785667419, -3.333997964859009, 0.7349817156791687, -2.3300042152404785, 0.37156131863594055, -0.6441475749015808, -0.6653284430503845, -0.7429379224777222, 0.036325521767139435, 0.0400901660323143, 0.6197296977043152, 0.739234447479248, -0.46324560046195984, 0.14665649831295013, 1.2907423973083496, 0.16316071152687073, -0.0570133775472641, -1.6206603050231934, -1.4446855783462524, -0.5889273881912231, 0.8108586668968201, -1.5479599237442017, -0.5918468832969666, -1.488057255744934, 0.14715614914894104, 0.45735645294189453, 1.011626124382019, -0.8413377404212952, -1.0522308349609375, 0.13020238280296326, 0.659566342830658, 0.6140164732933044, 1.5512009859085083, 13.569733619689941, -1.037151575088501, -1.0740387439727783, -0.7633157968521118, 1.442948579788208, 0.4109859764575958, 0.6243058443069458, 1.9849101305007935, -0.5198934674263, -0.14340408146381378, -2.0816428661346436, 1.5308020114898682, -3.8652286529541016, -0.7699278593063354, -1.0006827116012573, -1.0803022384643555, -0.3954876661300659, 0.11275474727153778, -0.03385986015200615, 0.6207625269889832, -0.08841376006603241, 0.40844669938087463, 0.2992890775203705, 1.162818431854248, 1.672940969467163, -0.4040423631668091, -0.13218937814235687, -0.1970667839050293, 0.6757615804672241, 1.7691333293914795, 0.48329758644104004, 0.3156685531139374, -0.1499066948890686, 0.6868475079536438]}\n",
      "Epoch 1/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 2.0497 - a\n",
      "Epoch 1 - F1 Score: 0.5125\n",
      "Saved best model\n",
      "[0.5125219651733212]\n",
      "2336/2336 [==============================] - 14s 6ms/step - loss: 2.0496 - accuracy: 0.4481 - val_loss: 1.6662 - val_accuracy: 0.5380\n",
      "Epoch 2/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 1.5335 - ac\n",
      "Epoch 2 - F1 Score: 0.5387\n",
      "Saved best model\n",
      "[0.5125219651733212, 0.5386787763001156]\n",
      "2336/2336 [==============================] - 11s 5ms/step - loss: 1.5334 - accuracy: 0.5652 - val_loss: 1.5686 - val_accuracy: 0.5623\n",
      "Epoch 3/40\n",
      "260/260 [==============================] - 1s 2ms/step loss: 1.4\n",
      "Epoch 3 - F1 Score: 0.5712\n",
      "Saved best model\n",
      "[0.5125219651733212, 0.5386787763001156, 0.5712427530115027]\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 1.4022 - accuracy: 0.5981 - val_loss: 1.4992 - val_accuracy: 0.5880\n",
      "Epoch 4/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 1.3178 - ac\n",
      "Epoch 4 - F1 Score: 0.5855\n",
      "Saved best model\n",
      "[0.5125219651733212, 0.5386787763001156, 0.5712427530115027, 0.5854782516446947]\n",
      "2336/2336 [==============================] - 11s 5ms/step - loss: 1.3177 - accuracy: 0.6209 - val_loss: 1.4436 - val_accuracy: 0.5948\n",
      "Epoch 5/40\n",
      "260/260 [==============================] - 1s 2ms/step loss: 1.2\n",
      "Epoch 5 - F1 Score: 0.5868\n",
      "Saved best model\n",
      "[0.5125219651733212, 0.5386787763001156, 0.5712427530115027, 0.5854782516446947, 0.5868488542156862]\n",
      "2336/2336 [==============================] - 13s 6ms/step - loss: 1.2595 - accuracy: 0.6349 - val_loss: 1.4122 - val_accuracy: 0.6070\n",
      "Epoch 6/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 1.2201 - ac\n",
      "Epoch 6 - F1 Score: 0.6017\n",
      "Saved best model\n",
      "[0.5125219651733212, 0.5386787763001156, 0.5712427530115027, 0.5854782516446947, 0.5868488542156862, 0.6017177193832136]\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 1.2205 - accuracy: 0.6446 - val_loss: 1.3868 - val_accuracy: 0.6124\n",
      "Epoch 7/40\n",
      "260/260 [==============================] - 0s 2ms/step loss: 1.1837 - \n",
      "Epoch 7 - F1 Score: 0.6038\n",
      "Saved best model\n",
      "[0.5125219651733212, 0.5386787763001156, 0.5712427530115027, 0.5854782516446947, 0.5868488542156862, 0.6017177193832136, 0.6038375246698544]\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 1.1838 - accuracy: 0.6529 - val_loss: 1.3869 - val_accuracy: 0.6174\n",
      "Epoch 8/40\n",
      "260/260 [==============================] - 0s 2ms/step loss: 1.1489 - \n",
      "2336/2336 [==============================] - 13s 5ms/step - loss: 1.1494 - accuracy: 0.6643 - val_loss: 1.4367 - val_accuracy: 0.6057\n",
      "Epoch 9/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 1.1238 - ac\n",
      "Epoch 9 - F1 Score: 0.6340\n",
      "Saved best model\n",
      "[0.5125219651733212, 0.5386787763001156, 0.5712427530115027, 0.5854782516446947, 0.5868488542156862, 0.6017177193832136, 0.6038375246698544, 0.6030407847639883, 0.6339759139083321]\n",
      "2336/2336 [==============================] - 11s 5ms/step - loss: 1.1235 - accuracy: 0.6686 - val_loss: 1.3108 - val_accuracy: 0.6411\n",
      "Epoch 10/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 1.0995 - ac\n",
      "2336/2336 [==============================] - 11s 5ms/step - loss: 1.0999 - accuracy: 0.6754 - val_loss: 1.3847 - val_accuracy: 0.6216\n",
      "Epoch 11/40\n",
      "260/260 [==============================] - 0s 2ms/step loss: 1.0782 \n",
      "2336/2336 [==============================] - 11s 5ms/step - loss: 1.0781 - accuracy: 0.6795 - val_loss: 1.3611 - val_accuracy: 0.6246\n",
      "Epoch 12/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 1.0599 - ac\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 1.0598 - accuracy: 0.6833 - val_loss: 1.3990 - val_accuracy: 0.6298\n",
      "Epoch 13/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 1.0373 - ac\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 1.0374 - accuracy: 0.6915 - val_loss: 1.4402 - val_accuracy: 0.6130\n",
      "Epoch 14/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 1.0248 - accu\n",
      "2336/2336 [==============================] - 11s 5ms/step - loss: 1.0250 - accuracy: 0.6932 - val_loss: 1.3611 - val_accuracy: 0.6398\n",
      "Epoch 15/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 1.0102 - accu\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 1.0101 - accuracy: 0.6968 - val_loss: 1.3817 - val_accuracy: 0.6265\n",
      "Epoch 16/40\n",
      "260/260 [==============================] - 1s 2ms/step loss: 0.994\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.9944 - accuracy: 0.7007 - val_loss: 1.4025 - val_accuracy: 0.6283\n",
      "Epoch 17/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.9839 - ac\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.9846 - accuracy: 0.7030 - val_loss: 1.4168 - val_accuracy: 0.6262\n",
      "Epoch 18/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.9703 - ac\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.9700 - accuracy: 0.7076 - val_loss: 1.4273 - val_accuracy: 0.6224\n",
      "Epoch 19/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.9577 - \n",
      "2336/2336 [==============================] - 11s 5ms/step - loss: 0.9580 - accuracy: 0.7115 - val_loss: 1.4616 - val_accuracy: 0.6106\n",
      "Epoch 20/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.9478 - ac\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.9484 - accuracy: 0.7126 - val_loss: 1.4135 - val_accuracy: 0.6358\n",
      "Epoch 21/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.9386 - \n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.9389 - accuracy: 0.7153 - val_loss: 1.4458 - val_accuracy: 0.6311\n",
      "Epoch 22/40\n",
      "260/260 [==============================] - 0s 2ms/step loss: 0.9232 \n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.9231 - accuracy: 0.7186 - val_loss: 1.4269 - val_accuracy: 0.6280\n",
      "Epoch 23/40\n",
      "260/260 [==============================] - 1s 2ms/step loss: 0\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.9170 - accuracy: 0.7194 - val_loss: 1.4730 - val_accuracy: 0.6265\n",
      "Epoch 24/40\n",
      "260/260 [==============================] - 0s 2ms/step loss: 0.9089 \n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.9089 - accuracy: 0.7223 - val_loss: 1.5100 - val_accuracy: 0.6156\n",
      "Epoch 25/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.8962 - \n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.8962 - accuracy: 0.7255 - val_loss: 1.4653 - val_accuracy: 0.6271\n",
      "Epoch 26/40\n",
      "260/260 [==============================] - 0s 2ms/step loss: 0.8889 \n",
      "2336/2336 [==============================] - 11s 5ms/step - loss: 0.8891 - accuracy: 0.7265 - val_loss: 1.4784 - val_accuracy: 0.6289\n",
      "Epoch 27/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.8815 - ac\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.8819 - accuracy: 0.7292 - val_loss: 1.4689 - val_accuracy: 0.6292\n",
      "Epoch 28/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.8732 - \n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.8730 - accuracy: 0.7300 - val_loss: 1.4727 - val_accuracy: 0.6342\n",
      "Epoch 29/40\n",
      "260/260 [==============================] - 1s 2ms/step loss: 0.862\n",
      "2336/2336 [==============================] - 14s 6ms/step - loss: 0.8623 - accuracy: 0.7337 - val_loss: 1.4986 - val_accuracy: 0.6260\n",
      "Epoch 30/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.8564 - ac\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.8564 - accuracy: 0.7355 - val_loss: 1.4986 - val_accuracy: 0.6303\n",
      "Epoch 31/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.8476 - accu\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.8479 - accuracy: 0.7366 - val_loss: 1.5519 - val_accuracy: 0.6230\n",
      "Epoch 32/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.8464 - accu\n",
      "2336/2336 [==============================] - 14s 6ms/step - loss: 0.8464 - accuracy: 0.7396 - val_loss: 1.5293 - val_accuracy: 0.6288\n",
      "Epoch 33/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.8357 - ac\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.8355 - accuracy: 0.7409 - val_loss: 1.5140 - val_accuracy: 0.6251\n",
      "Epoch 34/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.8309 - accu\n",
      "2336/2336 [==============================] - 11s 5ms/step - loss: 0.8308 - accuracy: 0.7428 - val_loss: 1.5410 - val_accuracy: 0.6306\n",
      "Epoch 35/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.8220 - \n",
      "2336/2336 [==============================] - 11s 5ms/step - loss: 0.8223 - accuracy: 0.7455 - val_loss: 1.5224 - val_accuracy: 0.6306\n",
      "Epoch 36/40\n",
      "260/260 [==============================] - 0s 2ms/step loss: 0.8206 - \n",
      "2336/2336 [==============================] - 13s 5ms/step - loss: 0.8205 - accuracy: 0.7441 - val_loss: 1.5247 - val_accuracy: 0.6343\n",
      "Epoch 37/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.8107 - ac\n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.8107 - accuracy: 0.7464 - val_loss: 1.5818 - val_accuracy: 0.6304\n",
      "Epoch 38/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.8046 - \n",
      "2336/2336 [==============================] - 12s 5ms/step - loss: 0.8045 - accuracy: 0.7492 - val_loss: 1.5641 - val_accuracy: 0.6360\n",
      "Epoch 39/40\n",
      "260/260 [==============================] - 0s 1ms/step loss: 0.7978 - ac\n",
      "2336/2336 [==============================] - 13s 6ms/step - loss: 0.7977 - accuracy: 0.7525 - val_loss: 1.6592 - val_accuracy: 0.6174\n",
      "Epoch 40/40\n",
      "260/260 [==============================] - 1s 2ms/step loss: 0.798\n",
      "2336/2336 [==============================] - 18s 8ms/step - loss: 0.7981 - accuracy: 0.7511 - val_loss: 1.5932 - val_accuracy: 0.6234\n",
      "444/444 [==============================] - 1s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8935    0.3607    0.5140      1070\n",
      "         120     0.3219    0.8112    0.4609       196\n",
      "         125     0.5465    0.7293    0.6248       532\n",
      "         134     0.5000    0.6316    0.5581        19\n",
      "         189     0.6792    0.6050    0.6400       119\n",
      "         190     0.6063    0.7700    0.6784       200\n",
      "          20     0.4309    0.1926    0.2662       810\n",
      "         200     0.7128    0.3407    0.4610       590\n",
      "         203     0.4667    0.5185    0.4912        27\n",
      "          22     0.8785    0.7819    0.8274       518\n",
      "         254     0.0000    0.0000    0.0000        34\n",
      "         255     0.2966    0.5224    0.3784        67\n",
      "         264     0.5368    0.6521    0.5889       503\n",
      "         269     0.3564    0.3396    0.3478       106\n",
      "         276     0.2110    0.3594    0.2659        64\n",
      "         284     0.4318    0.1545    0.2275       123\n",
      "         287     0.3613    0.4982    0.4189       285\n",
      "         295     0.6364    0.6049    0.6203        81\n",
      "         306     0.2381    0.3191    0.2727        94\n",
      "         310     0.6890    0.8273    0.7518       249\n",
      "         312     0.1275    0.3095    0.1806        42\n",
      "         319     0.2262    0.3725    0.2815        51\n",
      "         326     0.1111    0.0323    0.0500        31\n",
      "         327     0.2553    0.3429    0.2927        35\n",
      "         345     0.2083    0.1923    0.2000        26\n",
      "         347     0.2373    0.5833    0.3373        24\n",
      "         352     0.5194    0.8565    0.6467       453\n",
      "         362     0.5694    0.6721    0.6165       122\n",
      "         399     0.4178    0.4847    0.4488       262\n",
      "         400     0.2712    0.3478    0.3048       138\n",
      "         401     0.3810    0.4615    0.4174        52\n",
      "         415     0.4478    0.7143    0.5505        42\n",
      "         416     0.5163    0.8277    0.6359       325\n",
      "         426     0.8571    0.2857    0.4286        42\n",
      "         427     0.4085    0.6591    0.5043        44\n",
      "         434     0.2875    0.8196    0.4257       194\n",
      "         476     0.6207    0.8072    0.7018       223\n",
      "         502     0.5789    0.7196    0.6417       107\n",
      "         522     0.4095    0.4778    0.4410        90\n",
      "         532     0.1984    0.5682    0.2941        44\n",
      "          59     0.4746    0.7706    0.5874       109\n",
      "         601     0.5972    0.6056    0.6014        71\n",
      "         611     0.7475    0.8043    0.7749        92\n",
      "         617     0.4340    0.6053    0.5055        38\n",
      "         639     0.1525    0.3214    0.2069        28\n",
      "         668     0.0486    0.1556    0.0741        45\n",
      "         732     0.1958    0.2857    0.2324        98\n",
      "          74     0.0669    0.2958    0.1091        71\n",
      "         755     0.2424    0.2857    0.2623        28\n",
      "          77     0.3489    0.5541    0.4282       148\n",
      "         770     0.1667    0.4068    0.2365        59\n",
      "         772     0.5556    0.4412    0.4918        34\n",
      "          78     0.4845    0.5811    0.5284       296\n",
      "         787     0.6460    0.4101    0.5017       890\n",
      "          79     0.9549    0.5536    0.7009      2256\n",
      "         798     0.6291    0.7364    0.6786       129\n",
      "         835     0.3059    0.6341    0.4127        41\n",
      "         843     0.6667    0.4706    0.5517        34\n",
      "         862     0.5217    0.5455    0.5333       220\n",
      "         863     0.2128    0.0847    0.1212       118\n",
      "          89     0.9659    0.5622    0.7107       957\n",
      "         908     0.6316    0.5000    0.5581        24\n",
      "         918     0.4921    0.6889    0.5741        90\n",
      "          94     0.2933    0.5514    0.3829       292\n",
      "\n",
      "    accuracy                         0.5363     14202\n",
      "   macro avg     0.4418    0.5063    0.4462     14202\n",
      "weighted avg     0.6373    0.5363    0.5472     14202\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_train.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super(F1ScoreCallback, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_f1 = 0.0\n",
    "        self.best_model = None\n",
    "        self.f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_val_pred = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        f1 = f1_score(self.y_val, y_val_pred, average='weighted')\n",
    "        self.f1_scores.append(f1)\n",
    "        \n",
    "\n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "            self.best_model = self.model\n",
    "            print(f\"Epoch {epoch + 1} - F1 Score: {f1:.4f}\")\n",
    "            print(\"Saved best model\")\n",
    "            print(self.f1_scores)\n",
    "\n",
    "with open('phi_descr_comparison_train.pickle', 'rb') as f1:\n",
    "    balanced = pickle.load(f1)\n",
    "print(balanced[0])\n",
    "with open('phi_descr_comparison_test_0.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "train = np.array([item['cve_description_phi'] for item in balanced if item['cwe'] != 'None'])\n",
    "test = np.array([item['cwe'] for item in balanced if item['cwe'] != 'None'])\n",
    "np.random.seed(42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,test,test_size=0.1,random_state=42)\n",
    "\n",
    "X_test = np.array([item['cve_description_phi'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "label_encoder_train = LabelEncoder()\n",
    "y_train_encoded = label_encoder_train.fit_transform(y_train)\n",
    "label_encoder_test = LabelEncoder()\n",
    "y_test_encoded = label_encoder_test.fit_transform(y_test)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1_callback = F1ScoreCallback(X_val, label_encoder_train.transform(y_val))\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, epochs=40, batch_size=32, validation_data=(X_val, label_encoder_train.transform(y_val)), verbose=1, callbacks=[f1_callback])\n",
    "\n",
    "best_model = f1_callback.best_model\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'CWE_classes.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))\n",
    "\n",
    "joblib.dump(label_encoder_train, 'label_encoder_train.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference based on CVE description with Phi-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444/444 [==============================] - 29s 64ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8935    0.3607    0.5140      1070\n",
      "         120     0.3219    0.8112    0.4609       196\n",
      "         125     0.5465    0.7293    0.6248       532\n",
      "         134     0.5000    0.6316    0.5581        19\n",
      "         189     0.6792    0.6050    0.6400       119\n",
      "         190     0.6063    0.7700    0.6784       200\n",
      "          20     0.4309    0.1926    0.2662       810\n",
      "         200     0.7128    0.3407    0.4610       590\n",
      "         203     0.4667    0.5185    0.4912        27\n",
      "          22     0.8785    0.7819    0.8274       518\n",
      "         254     0.0000    0.0000    0.0000        34\n",
      "         255     0.2966    0.5224    0.3784        67\n",
      "         264     0.5368    0.6521    0.5889       503\n",
      "         269     0.3564    0.3396    0.3478       106\n",
      "         276     0.2110    0.3594    0.2659        64\n",
      "         284     0.4318    0.1545    0.2275       123\n",
      "         287     0.3613    0.4982    0.4189       285\n",
      "         295     0.6364    0.6049    0.6203        81\n",
      "         306     0.2381    0.3191    0.2727        94\n",
      "         310     0.6890    0.8273    0.7518       249\n",
      "         312     0.1275    0.3095    0.1806        42\n",
      "         319     0.2262    0.3725    0.2815        51\n",
      "         326     0.1111    0.0323    0.0500        31\n",
      "         327     0.2553    0.3429    0.2927        35\n",
      "         345     0.2083    0.1923    0.2000        26\n",
      "         347     0.2373    0.5833    0.3373        24\n",
      "         352     0.5194    0.8565    0.6467       453\n",
      "         362     0.5694    0.6721    0.6165       122\n",
      "         399     0.4178    0.4847    0.4488       262\n",
      "         400     0.2712    0.3478    0.3048       138\n",
      "         401     0.3810    0.4615    0.4174        52\n",
      "         415     0.4478    0.7143    0.5505        42\n",
      "         416     0.5163    0.8277    0.6359       325\n",
      "         426     0.8571    0.2857    0.4286        42\n",
      "         427     0.4085    0.6591    0.5043        44\n",
      "         434     0.2875    0.8196    0.4257       194\n",
      "         476     0.6207    0.8072    0.7018       223\n",
      "         502     0.5789    0.7196    0.6417       107\n",
      "         522     0.4095    0.4778    0.4410        90\n",
      "         532     0.1984    0.5682    0.2941        44\n",
      "          59     0.4746    0.7706    0.5874       109\n",
      "         601     0.5972    0.6056    0.6014        71\n",
      "         611     0.7475    0.8043    0.7749        92\n",
      "         617     0.4340    0.6053    0.5055        38\n",
      "         639     0.1525    0.3214    0.2069        28\n",
      "         668     0.0486    0.1556    0.0741        45\n",
      "         732     0.1958    0.2857    0.2324        98\n",
      "          74     0.0669    0.2958    0.1091        71\n",
      "         755     0.2424    0.2857    0.2623        28\n",
      "          77     0.3489    0.5541    0.4282       148\n",
      "         770     0.1667    0.4068    0.2365        59\n",
      "         772     0.5556    0.4412    0.4918        34\n",
      "          78     0.4845    0.5811    0.5284       296\n",
      "         787     0.6460    0.4101    0.5017       890\n",
      "          79     0.9549    0.5536    0.7009      2256\n",
      "         798     0.6291    0.7364    0.6786       129\n",
      "         835     0.3059    0.6341    0.4127        41\n",
      "         843     0.6667    0.4706    0.5517        34\n",
      "         862     0.5217    0.5455    0.5333       220\n",
      "         863     0.2128    0.0847    0.1212       118\n",
      "          89     0.9659    0.5622    0.7107       957\n",
      "         908     0.6316    0.5000    0.5581        24\n",
      "         918     0.4921    0.6889    0.5741        90\n",
      "          94     0.2933    0.5514    0.3829       292\n",
      "\n",
      "    accuracy                         0.5363     14202\n",
      "   macro avg     0.4418    0.5063    0.4462     14202\n",
      "weighted avg     0.6373    0.5363    0.5472     14202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Save the best model\n",
    "with open('phi_descr_comparison_test_0.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "X_test = np.array([item['cve_description_phi'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "best_model=joblib.load('best_model_descr.joblib')\n",
    "label_encoder_train=joblib.load('label_encoder_train_descr.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
